{
  "text": " Right, so it seems like the audio files are getting onto the phone nicely, and then from the phone onto the laptop nicely, so that whole system is working really really well. Very happy with that. Obviously the next thing is to try and find some way of dealing with them, which shouldn't be too hard, but it's not going to be trivial obviously. Okay, so for thesis stuff, it looks like the section, subsection, whatever-y thing is working really well, so I think at the moment what I want to do is just go over each chapter in each section and fill out just all of the sections and subsections. I won't go deeper than subsections, that doesn't seem reasonable. But if I can do that, just to have them all, I can basically just look through each and just say, okay, is this section done, is this subsection done? And the other advantage of doing it this way I think is I'll actually, in the overlay, I'll build up all the sections as well, so I can see how they're progressing as well. I think that's going to help quite a lot. I need to figure out a name for the part of the chapter or section or whatever that just is by itself, so isn't going into the section, so that probably just stays in the thing. Maybe I call it like section zero? Not sure, no, no, we'll just put that in the main thing. Like the introduction to the introduction chapter, for instance, should just go in the introduction chapter note. I think that makes sense, I think that's reasonable. Okay, cool, so that'll be fine. I've got everything kind of sorted out like that. Then for each thing, yeah, fill out the sections and subsections, that'll work really well. So that's that. The other big one that I'm doing at the moment is DBAS. I've emailed Saul, which is good. I've sent the presentation off to Ryan, which is good. I need to actually clean up that presentation. DBAS stuff is coming along. I need to figure out what I want the website to look like, I think. Yeah, I'll think about that, not sure. But I like the idea of using this as like a way of learning a bit more advanced CSS and JavaScript-y stuff. I think that's really useful. There's a lot that can be done with that that I'm quite excited for. Yeah, so there's that. What was I also going to say? Yeah, this Pathfinder thing. It's a really cool looking project. I definitely should read through the archive to see how it works. But I really like the idea of... Okay, so there's a few places where they've got like open AI stuff, right? Which seems to be that's the side of their thing doing the LLM. Fair enough. Okay, great. So I think the first thing I want to do is just get my own open AI key, then see if I can just get it to run locally. Because if I can, great, very happy with that. Let's go. Um, however... Oh, yeah, yeah. So if I can get it to run locally, we're very happy. And we are golden. And then the next thing would be... Okay, so how do I say instead of going into the open AI key, go into a local LLM? And I could do that with like, I guess, kobold or silly tavern or whatever, but it's probably easier to just say it's in Python already. Just get like the hugging face transformers, I think it is, package, and then use that to get the LLM stuff up and running. Which again, I want to learn how to do anyway, because I want to have a local LLM do summarization and stuff with my notes. So we'll look into that. If I can get all of that running on like the eight gigs of VRAM that I've got, then that's a really good space to be in, you know? Cool. It looks like their stuff is CPU only at the moment, which, I mean, if it runs that fast, CPU only. No, if they're using open AI tokens, then it sounds like they've just got like a set of things that they're working off of. And that's why it runs fast, because they're basically just asking open AI to do it for them. Um, so yeah, that definitely seems possible. And it's interesting for sure. Okay, so Nico's asked me to do Julia stuff, give a workshop in Julia, which sounds awesome. Very excited for that. I think I really like the idea of this. So I think what I need to do is create a Google form or something, which basically asks, you know, well, what are the questions it would ask? What language do you write in? Obviously, Python's going to be an option, and we'll get some of the other key players, R, you know, C, C++. We'll get, what's the other big one? Rust. Yeah, we'll get all those ones, right? I'll put Julia in there, just in case. That'll be fun. And then, you know, what do you do with your code, right? Is another question. So like, some options I'll put in there would be something like write, you know, quick and dirty scripts would be one. I would say write programs for me to use, write programs for others to use, write packages to distribute, right? That's the kind of thing. And then there'll be questions of like, okay, well, in what space, how do you code? So this would be like, you know, I code in a GUI, VS code, whatever. Like, oh, sorry, I code in a project, C, VS code, whatever. I code in a notebook, like Jupyter notebook. I code locally. I code on a server. All these kinds of questions. And just get an idea of how people do computing in Stromlo. I think would be very useful. Yeah, I agree with that. And then get some basic instructions for like, how do you get Julia up and running on whatever device you're on, right? And basically what I want them to have is a directory with a project.toml in it. And that's about it. And that'll be good for them to have to start up. If they've got that, we're happy, we're golden. And then the things I actually want to show So why should someone use Julia? I really like the idea of titling the talk why I use Julia and you probably shouldn't. I think that's a great, great talk title. Because I think within astronomy, there are a few spaces where Julia has really, is going to be really, really useful. But I think the issue in astronomy especially is that so much of the work we do is going to be associated with a very specific thing, right? As in like, if I look at DBAS, Julia is not going to come into DBAS, right? I could use it instead of Django, but Django is already set up for that. We have PyWives, which obviously is a Python interface. So I could use it for that, but we don't need to. We've already got that. I think Julia for an astronomer is most useful if the astronomer is writing code. And specifically, I think it's going to be most useful if you're writing code for others to use. Yeah, so that's a good way of doing it. I might kind of do it as different sizes of whatever, right? So I'll say something like, you know, if what you do is you use Python to create quick and dirty scripts, here's Julia being used for quick and dirty scripts, you know? So this would be something like, you know, what do you get for free if you use Julia for quick and dirty scripts instead of Python? Well, the kindest thing you get for free is you get package management for free without having to worry about which conda environment, whatever you're using. Your quick and dirty script can be slightly less quick and dirty quite easily. For instance, yeah, it's just so much of it is like the IO side of things is the slow part. Because you wouldn't want plotting as a quick and dirty thing in Julia, right? That's not going to work out. So what are quick and dirty things that people do in Python right now? Okay, so one thought that I had is a quick and dirty thing you could do is you've got data of some type and you want to quickly open it up and play around with it and close it again, right? That seems like a reasonable thing. Okay, so I've got data that is like a thing that's a million lines long or something ridiculous. And I'll probably set something up like this to say, okay, here's some data that's really, really long and on each thing I need to do something and then save that in another data file, right? Great, okay, so what we want to do is say like for each line in the thing, do this thing and then stop. Cool, very happy with that. Okay, so how would you do that in Python? Here's the setup. How to do that in Julia is the setup. Now, obviously, I'll then show and say, okay, and here's kind of the difference in speed between the two, right? And the difference in complexity. And I'll try to make the Julia look as close to the Python as I can. And I think that's going to be really important because what I then want to do is say, okay, let's look at how we would speed this up in the two languages, because I think this is the really important thing. Python is very good at quick and dirty, but taking quick and dirty and turning it into better and faster and more performant and optimized is hard. Julia is fairly equivalent to Python for quick and dirty, right? Slightly different syntax, but fundamentally you're doing roughly the same thing, but turning it into something that is performant and optimized is much easier. Yeah, I really like that framing of the thing. So what I'll do is I'll say something along the lines of, okay, so we're going to go through the manner in which someone would create a... end up with a useful tool in astronomy. Because I think I want to phrase Julia as the reason, the thing you should use this for is building tools in astronomy, right? When it comes to here's some data plotted for a paper, Python's fine for that. Julia can do that, absolutely. But Julia can't necessarily do that better than Python, right? And it comes to... like if you're doing more advanced computing stuff. So yeah, I mean it's worth mentioning, like if you're doing more advanced computing stuff, like doing machine learning, doing high performance computing, doing GPU computing, all of these things are absolutely doable in Julia and have strong things. And I'll say it, yeah. Yeah, okay. So the introduction I'll go through, these are like the highlights of Julia. But when it comes to how you guys and me and I are most likely going to use it, you need to look at how we use code in general, right? Most of us are not computer scientists, we're astronomers. Which means most of the time, the code we write is in the service of doing astronomy. We're not writing code for the sake of code. And I say we, obviously I do that a lot. But what I mean is that the function of code within astronomy is to produce something that can be used. It doesn't need to be... But yeah, produce a very specialized tool that can be used, right? If you're looking at languages like Rust and C++ and all these other languages, they're very good at building very powerful general tools, right? So this is a tool that can be used by anyone for something big, right? You're looking at like Linux or a web browser or something like that. That's what those tools are used for. If you look at Python, there's kind of two branches. Pure Python, quick and dirty script that you run a few times and then never again. Or a wrapper around a general purpose tool, right? So this creates a general purpose tool in C or C++ or Rust. And then using that tool is really obnoxious. And, you know, making that tool play nicely with file writing and with plotting and with all of the other things that we like to do. That's all annoying. And so we do a Python wrapper to make it easier to use the tool, right? Oftentimes Python is a way of using tools that other people have made. Right? But what that means is you kind of need... If the tool doesn't exist and you want the tool, then you need to kind of know one language for making the tool so that other people can use it and another language for making tools so that other people want to use it. And the way Julia presents itself is doing both. So what I want to do is kind of work through the process of someone trying to build a new astronomy tool. This is obviously going to be somewhat of a contrived example, but just as an example, here's this thing. Now, when you first start with it, you start having it be or whatever, and then from there you move on to it being a bit nicer and then blah blah blah. Okay, that's a cool idea. Just about to pick Eve up, so I'm going to stop here.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 8.08,
      "text": " Right, so it seems like the audio files are getting onto the phone nicely, and then from",
      "tokens": [
        50363,
        6498,
        11,
        523,
        340,
        2331,
        588,
        262,
        6597,
        3696,
        389,
        1972,
        4291,
        262,
        3072,
        16576,
        11,
        290,
        788,
        422,
        50767
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20701448307480924,
      "compression_ratio": 1.6150234741784038,
      "no_speech_prob": 0.09583532065153122
    },
    {
      "id": 1,
      "seek": 0,
      "start": 8.08,
      "end": 13.52,
      "text": " the phone onto the laptop nicely, so that whole system is working really really well.",
      "tokens": [
        50767,
        262,
        3072,
        4291,
        262,
        13224,
        16576,
        11,
        523,
        326,
        2187,
        1080,
        318,
        1762,
        1107,
        1107,
        880,
        13,
        51039
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20701448307480924,
      "compression_ratio": 1.6150234741784038,
      "no_speech_prob": 0.09583532065153122
    },
    {
      "id": 2,
      "seek": 0,
      "start": 13.52,
      "end": 15.44,
      "text": " Very happy with that.",
      "tokens": [
        51039,
        9576,
        3772,
        351,
        326,
        13,
        51135
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20701448307480924,
      "compression_ratio": 1.6150234741784038,
      "no_speech_prob": 0.09583532065153122
    },
    {
      "id": 3,
      "seek": 0,
      "start": 15.44,
      "end": 20.96,
      "text": " Obviously the next thing is to try and find some way of dealing with them, which shouldn't",
      "tokens": [
        51135,
        16263,
        262,
        1306,
        1517,
        318,
        284,
        1949,
        290,
        1064,
        617,
        835,
        286,
        7219,
        351,
        606,
        11,
        543,
        6584,
        470,
        51411
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20701448307480924,
      "compression_ratio": 1.6150234741784038,
      "no_speech_prob": 0.09583532065153122
    },
    {
      "id": 4,
      "seek": 0,
      "start": 20.96,
      "end": 24.400000000000002,
      "text": " be too hard, but it's not going to be trivial obviously.",
      "tokens": [
        51411,
        307,
        1165,
        1327,
        11,
        475,
        340,
        338,
        407,
        1016,
        284,
        307,
        20861,
        6189,
        13,
        51583
      ],
      "temperature": 0.0,
      "avg_logprob": -0.20701448307480924,
      "compression_ratio": 1.6150234741784038,
      "no_speech_prob": 0.09583532065153122
    },
    {
      "id": 5,
      "seek": 2440,
      "start": 24.959999999999997,
      "end": 30.479999999999997,
      "text": " Okay, so for thesis stuff, it looks like the section, subsection, whatever-y thing is working",
      "tokens": [
        50391,
        16805,
        11,
        523,
        329,
        21554,
        3404,
        11,
        340,
        3073,
        588,
        262,
        2665,
        11,
        8371,
        11,
        4232,
        12,
        88,
        1517,
        318,
        1762,
        50667
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1468296371588186,
      "compression_ratio": 1.8492063492063493,
      "no_speech_prob": 0.06868243217468262
    },
    {
      "id": 6,
      "seek": 2440,
      "start": 30.479999999999997,
      "end": 34.879999999999995,
      "text": " really well, so I think at the moment what I want to do is just go over each chapter",
      "tokens": [
        50667,
        1107,
        880,
        11,
        523,
        314,
        892,
        379,
        262,
        2589,
        644,
        314,
        765,
        284,
        466,
        318,
        655,
        467,
        625,
        1123,
        6843,
        50887
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1468296371588186,
      "compression_ratio": 1.8492063492063493,
      "no_speech_prob": 0.06868243217468262
    },
    {
      "id": 7,
      "seek": 2440,
      "start": 34.879999999999995,
      "end": 39.76,
      "text": " in each section and fill out just all of the sections and subsections.",
      "tokens": [
        50887,
        287,
        1123,
        2665,
        290,
        6070,
        503,
        655,
        477,
        286,
        262,
        9004,
        290,
        46310,
        13,
        51131
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1468296371588186,
      "compression_ratio": 1.8492063492063493,
      "no_speech_prob": 0.06868243217468262
    },
    {
      "id": 8,
      "seek": 2440,
      "start": 39.76,
      "end": 42.4,
      "text": " I won't go deeper than subsections, that doesn't seem reasonable.",
      "tokens": [
        51131,
        314,
        1839,
        470,
        467,
        9211,
        621,
        46310,
        11,
        326,
        1595,
        470,
        1283,
        6397,
        13,
        51263
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1468296371588186,
      "compression_ratio": 1.8492063492063493,
      "no_speech_prob": 0.06868243217468262
    },
    {
      "id": 9,
      "seek": 2440,
      "start": 43.28,
      "end": 47.68,
      "text": " But if I can do that, just to have them all, I can basically just look through each and",
      "tokens": [
        51307,
        887,
        611,
        314,
        460,
        466,
        326,
        11,
        655,
        284,
        423,
        606,
        477,
        11,
        314,
        460,
        6209,
        655,
        804,
        832,
        1123,
        290,
        51527
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1468296371588186,
      "compression_ratio": 1.8492063492063493,
      "no_speech_prob": 0.06868243217468262
    },
    {
      "id": 10,
      "seek": 2440,
      "start": 47.68,
      "end": 50.72,
      "text": " just say, okay, is this section done, is this subsection done?",
      "tokens": [
        51527,
        655,
        910,
        11,
        8788,
        11,
        318,
        428,
        2665,
        1760,
        11,
        318,
        428,
        8371,
        1760,
        30,
        51679
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1468296371588186,
      "compression_ratio": 1.8492063492063493,
      "no_speech_prob": 0.06868243217468262
    },
    {
      "id": 11,
      "seek": 5072,
      "start": 50.72,
      "end": 56.08,
      "text": " And the other advantage of doing it this way I think is I'll actually, in the overlay,",
      "tokens": [
        50363,
        843,
        262,
        584,
        4621,
        286,
        1804,
        340,
        428,
        835,
        314,
        892,
        318,
        314,
        1183,
        1682,
        11,
        287,
        262,
        33345,
        11,
        50631
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13847888433016264,
      "compression_ratio": 1.696969696969697,
      "no_speech_prob": 0.008391892537474632
    },
    {
      "id": 12,
      "seek": 5072,
      "start": 56.08,
      "end": 60.48,
      "text": " I'll build up all the sections as well, so I can see how they're progressing as well.",
      "tokens": [
        50631,
        314,
        1183,
        1382,
        510,
        477,
        262,
        9004,
        355,
        880,
        11,
        523,
        314,
        460,
        766,
        703,
        484,
        821,
        37335,
        355,
        880,
        13,
        50851
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13847888433016264,
      "compression_ratio": 1.696969696969697,
      "no_speech_prob": 0.008391892537474632
    },
    {
      "id": 13,
      "seek": 5072,
      "start": 61.04,
      "end": 62.879999999999995,
      "text": " I think that's going to help quite a lot.",
      "tokens": [
        50879,
        314,
        892,
        326,
        338,
        1016,
        284,
        1037,
        2407,
        257,
        1256,
        13,
        50971
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13847888433016264,
      "compression_ratio": 1.696969696969697,
      "no_speech_prob": 0.008391892537474632
    },
    {
      "id": 14,
      "seek": 5072,
      "start": 64.16,
      "end": 70.16,
      "text": " I need to figure out a name for the part of the chapter or section or whatever that just",
      "tokens": [
        51035,
        314,
        761,
        284,
        3785,
        503,
        257,
        1438,
        329,
        262,
        636,
        286,
        262,
        6843,
        393,
        2665,
        393,
        4232,
        326,
        655,
        51335
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13847888433016264,
      "compression_ratio": 1.696969696969697,
      "no_speech_prob": 0.008391892537474632
    },
    {
      "id": 15,
      "seek": 5072,
      "start": 70.16,
      "end": 78.16,
      "text": " is by itself, so isn't going into the section, so that probably just stays in the thing.",
      "tokens": [
        51335,
        318,
        416,
        2346,
        11,
        523,
        2125,
        470,
        1016,
        656,
        262,
        2665,
        11,
        523,
        326,
        2192,
        655,
        14768,
        287,
        262,
        1517,
        13,
        51735
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13847888433016264,
      "compression_ratio": 1.696969696969697,
      "no_speech_prob": 0.008391892537474632
    },
    {
      "id": 16,
      "seek": 7816,
      "start": 78.8,
      "end": 80.39999999999999,
      "text": " Maybe I call it like section zero?",
      "tokens": [
        50395,
        6674,
        314,
        869,
        340,
        588,
        2665,
        6632,
        30,
        50475
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15703058630470337,
      "compression_ratio": 1.7848605577689243,
      "no_speech_prob": 0.00952625460922718
    },
    {
      "id": 17,
      "seek": 7816,
      "start": 81.03999999999999,
      "end": 83.6,
      "text": " Not sure, no, no, we'll just put that in the main thing.",
      "tokens": [
        50507,
        1892,
        1654,
        11,
        645,
        11,
        645,
        11,
        356,
        1183,
        655,
        1234,
        326,
        287,
        262,
        1388,
        1517,
        13,
        50635
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15703058630470337,
      "compression_ratio": 1.7848605577689243,
      "no_speech_prob": 0.00952625460922718
    },
    {
      "id": 18,
      "seek": 7816,
      "start": 83.6,
      "end": 88.64,
      "text": " Like the introduction to the introduction chapter, for instance, should just go in the",
      "tokens": [
        50635,
        4525,
        262,
        9793,
        284,
        262,
        9793,
        6843,
        11,
        329,
        4554,
        11,
        815,
        655,
        467,
        287,
        262,
        50887
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15703058630470337,
      "compression_ratio": 1.7848605577689243,
      "no_speech_prob": 0.00952625460922718
    },
    {
      "id": 19,
      "seek": 7816,
      "start": 88.64,
      "end": 90.64,
      "text": " introduction chapter note.",
      "tokens": [
        50887,
        9793,
        6843,
        3465,
        13,
        50987
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15703058630470337,
      "compression_ratio": 1.7848605577689243,
      "no_speech_prob": 0.00952625460922718
    },
    {
      "id": 20,
      "seek": 7816,
      "start": 90.64,
      "end": 92.47999999999999,
      "text": " I think that makes sense, I think that's reasonable.",
      "tokens": [
        50987,
        314,
        892,
        326,
        1838,
        2565,
        11,
        314,
        892,
        326,
        338,
        6397,
        13,
        51079
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15703058630470337,
      "compression_ratio": 1.7848605577689243,
      "no_speech_prob": 0.00952625460922718
    },
    {
      "id": 21,
      "seek": 7816,
      "start": 92.47999999999999,
      "end": 94.32,
      "text": " Okay, cool, so that'll be fine.",
      "tokens": [
        51079,
        16805,
        11,
        3608,
        11,
        523,
        326,
        1183,
        307,
        3734,
        13,
        51171
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15703058630470337,
      "compression_ratio": 1.7848605577689243,
      "no_speech_prob": 0.00952625460922718
    },
    {
      "id": 22,
      "seek": 7816,
      "start": 95.84,
      "end": 97.6,
      "text": " I've got everything kind of sorted out like that.",
      "tokens": [
        51247,
        314,
        1053,
        1392,
        2279,
        1611,
        286,
        23243,
        503,
        588,
        326,
        13,
        51335
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15703058630470337,
      "compression_ratio": 1.7848605577689243,
      "no_speech_prob": 0.00952625460922718
    },
    {
      "id": 23,
      "seek": 7816,
      "start": 99.6,
      "end": 105.12,
      "text": " Then for each thing, yeah, fill out the sections and subsections, that'll work really well.",
      "tokens": [
        51435,
        3244,
        329,
        1123,
        1517,
        11,
        10194,
        11,
        6070,
        503,
        262,
        9004,
        290,
        46310,
        11,
        326,
        1183,
        670,
        1107,
        880,
        13,
        51711
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15703058630470337,
      "compression_ratio": 1.7848605577689243,
      "no_speech_prob": 0.00952625460922718
    },
    {
      "id": 24,
      "seek": 7816,
      "start": 105.12,
      "end": 105.67999999999999,
      "text": " So that's that.",
      "tokens": [
        51711,
        1406,
        326,
        338,
        326,
        13,
        51739
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15703058630470337,
      "compression_ratio": 1.7848605577689243,
      "no_speech_prob": 0.00952625460922718
    },
    {
      "id": 25,
      "seek": 10568,
      "start": 106.4,
      "end": 109.2,
      "text": " The other big one that I'm doing at the moment is DBAS.",
      "tokens": [
        50399,
        383,
        584,
        1263,
        530,
        326,
        314,
        1101,
        1804,
        379,
        262,
        2589,
        318,
        20137,
        1921,
        13,
        50539
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11883770067667224,
      "compression_ratio": 1.613861386138614,
      "no_speech_prob": 0.004226839169859886
    },
    {
      "id": 26,
      "seek": 10568,
      "start": 109.2,
      "end": 110.64,
      "text": " I've emailed Saul, which is good.",
      "tokens": [
        50539,
        314,
        1053,
        24315,
        31603,
        11,
        543,
        318,
        922,
        13,
        50611
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11883770067667224,
      "compression_ratio": 1.613861386138614,
      "no_speech_prob": 0.004226839169859886
    },
    {
      "id": 27,
      "seek": 10568,
      "start": 110.64,
      "end": 113.52000000000001,
      "text": " I've sent the presentation off to Ryan, which is good.",
      "tokens": [
        50611,
        314,
        1053,
        1908,
        262,
        10470,
        572,
        284,
        6047,
        11,
        543,
        318,
        922,
        13,
        50755
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11883770067667224,
      "compression_ratio": 1.613861386138614,
      "no_speech_prob": 0.004226839169859886
    },
    {
      "id": 28,
      "seek": 10568,
      "start": 113.52000000000001,
      "end": 116.64000000000001,
      "text": " I need to actually clean up that presentation.",
      "tokens": [
        50755,
        314,
        761,
        284,
        1682,
        3424,
        510,
        326,
        10470,
        13,
        50911
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11883770067667224,
      "compression_ratio": 1.613861386138614,
      "no_speech_prob": 0.004226839169859886
    },
    {
      "id": 29,
      "seek": 10568,
      "start": 119.28,
      "end": 121.28,
      "text": " DBAS stuff is coming along.",
      "tokens": [
        51043,
        20137,
        1921,
        3404,
        318,
        2406,
        1863,
        13,
        51143
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11883770067667224,
      "compression_ratio": 1.613861386138614,
      "no_speech_prob": 0.004226839169859886
    },
    {
      "id": 30,
      "seek": 10568,
      "start": 121.28,
      "end": 126.0,
      "text": " I need to figure out what I want the website to look like, I think.",
      "tokens": [
        51143,
        314,
        761,
        284,
        3785,
        503,
        644,
        314,
        765,
        262,
        3052,
        284,
        804,
        588,
        11,
        314,
        892,
        13,
        51379
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11883770067667224,
      "compression_ratio": 1.613861386138614,
      "no_speech_prob": 0.004226839169859886
    },
    {
      "id": 31,
      "seek": 10568,
      "start": 129.36,
      "end": 131.20000000000002,
      "text": " Yeah, I'll think about that, not sure.",
      "tokens": [
        51547,
        9425,
        11,
        314,
        1183,
        892,
        546,
        326,
        11,
        407,
        1654,
        13,
        51639
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11883770067667224,
      "compression_ratio": 1.613861386138614,
      "no_speech_prob": 0.004226839169859886
    },
    {
      "id": 32,
      "seek": 13120,
      "start": 131.83999999999997,
      "end": 136.48,
      "text": " But I like the idea of using this as like a way of learning a bit more advanced CSS",
      "tokens": [
        50395,
        887,
        314,
        588,
        262,
        2126,
        286,
        1262,
        428,
        355,
        588,
        257,
        835,
        286,
        4673,
        257,
        1643,
        517,
        6190,
        17391,
        50627
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1415732517715328,
      "compression_ratio": 1.6022727272727273,
      "no_speech_prob": 0.05159515514969826
    },
    {
      "id": 33,
      "seek": 13120,
      "start": 136.48,
      "end": 137.51999999999998,
      "text": " and JavaScript-y stuff.",
      "tokens": [
        50627,
        290,
        11933,
        12,
        88,
        3404,
        13,
        50679
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1415732517715328,
      "compression_ratio": 1.6022727272727273,
      "no_speech_prob": 0.05159515514969826
    },
    {
      "id": 34,
      "seek": 13120,
      "start": 138.16,
      "end": 139.2,
      "text": " I think that's really useful.",
      "tokens": [
        50711,
        314,
        892,
        326,
        338,
        1107,
        4465,
        13,
        50763
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1415732517715328,
      "compression_ratio": 1.6022727272727273,
      "no_speech_prob": 0.05159515514969826
    },
    {
      "id": 35,
      "seek": 13120,
      "start": 139.2,
      "end": 141.51999999999998,
      "text": " There's a lot that can be done with that that I'm quite excited for.",
      "tokens": [
        50763,
        1318,
        338,
        257,
        1256,
        326,
        460,
        307,
        1760,
        351,
        326,
        326,
        314,
        1101,
        2407,
        6568,
        329,
        13,
        50879
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1415732517715328,
      "compression_ratio": 1.6022727272727273,
      "no_speech_prob": 0.05159515514969826
    },
    {
      "id": 36,
      "seek": 13120,
      "start": 143.35999999999999,
      "end": 144.64,
      "text": " Yeah, so there's that.",
      "tokens": [
        50971,
        9425,
        11,
        523,
        612,
        338,
        326,
        13,
        51035
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1415732517715328,
      "compression_ratio": 1.6022727272727273,
      "no_speech_prob": 0.05159515514969826
    },
    {
      "id": 37,
      "seek": 13120,
      "start": 146.88,
      "end": 148.39999999999998,
      "text": " What was I also going to say?",
      "tokens": [
        51147,
        1867,
        373,
        314,
        635,
        1016,
        284,
        910,
        30,
        51223
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1415732517715328,
      "compression_ratio": 1.6022727272727273,
      "no_speech_prob": 0.05159515514969826
    },
    {
      "id": 38,
      "seek": 13120,
      "start": 149.2,
      "end": 150.64,
      "text": " Yeah, this Pathfinder thing.",
      "tokens": [
        51263,
        9425,
        11,
        428,
        37025,
        1517,
        13,
        51335
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1415732517715328,
      "compression_ratio": 1.6022727272727273,
      "no_speech_prob": 0.05159515514969826
    },
    {
      "id": 39,
      "seek": 13120,
      "start": 151.2,
      "end": 152.64,
      "text": " It's a really cool looking project.",
      "tokens": [
        51363,
        632,
        338,
        257,
        1107,
        3608,
        2045,
        1628,
        13,
        51435
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1415732517715328,
      "compression_ratio": 1.6022727272727273,
      "no_speech_prob": 0.05159515514969826
    },
    {
      "id": 40,
      "seek": 13120,
      "start": 152.64,
      "end": 156.16,
      "text": " I definitely should read through the archive to see how it works.",
      "tokens": [
        51435,
        314,
        4753,
        815,
        1100,
        832,
        262,
        15424,
        284,
        766,
        703,
        340,
        2499,
        13,
        51611
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1415732517715328,
      "compression_ratio": 1.6022727272727273,
      "no_speech_prob": 0.05159515514969826
    },
    {
      "id": 41,
      "seek": 13120,
      "start": 156.16,
      "end": 158.23999999999998,
      "text": " But I really like the idea of...",
      "tokens": [
        51611,
        887,
        314,
        1107,
        588,
        262,
        2126,
        286,
        986,
        51715
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1415732517715328,
      "compression_ratio": 1.6022727272727273,
      "no_speech_prob": 0.05159515514969826
    },
    {
      "id": 42,
      "seek": 15824,
      "start": 158.24,
      "end": 163.12,
      "text": " Okay, so there's a few places where they've got like open AI stuff, right?",
      "tokens": [
        50363,
        16805,
        11,
        523,
        612,
        338,
        257,
        1178,
        4113,
        810,
        484,
        1053,
        1392,
        588,
        1280,
        9552,
        3404,
        11,
        826,
        30,
        50607
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14179345603301147,
      "compression_ratio": 1.5339366515837105,
      "no_speech_prob": 0.004322201944887638
    },
    {
      "id": 43,
      "seek": 15824,
      "start": 164.0,
      "end": 168.64000000000001,
      "text": " Which seems to be that's the side of their thing doing the LLM.",
      "tokens": [
        50651,
        9022,
        2331,
        284,
        307,
        326,
        338,
        262,
        1735,
        286,
        511,
        1517,
        1804,
        262,
        27140,
        44,
        13,
        50883
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14179345603301147,
      "compression_ratio": 1.5339366515837105,
      "no_speech_prob": 0.004322201944887638
    },
    {
      "id": 44,
      "seek": 15824,
      "start": 169.36,
      "end": 169.92000000000002,
      "text": " Fair enough.",
      "tokens": [
        50919,
        7011,
        1576,
        13,
        50947
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14179345603301147,
      "compression_ratio": 1.5339366515837105,
      "no_speech_prob": 0.004322201944887638
    },
    {
      "id": 45,
      "seek": 15824,
      "start": 169.92000000000002,
      "end": 170.56,
      "text": " Okay, great.",
      "tokens": [
        50947,
        16805,
        11,
        1049,
        13,
        50979
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14179345603301147,
      "compression_ratio": 1.5339366515837105,
      "no_speech_prob": 0.004322201944887638
    },
    {
      "id": 46,
      "seek": 15824,
      "start": 170.56,
      "end": 174.0,
      "text": " So I think the first thing I want to do is just get my own open AI key,",
      "tokens": [
        50979,
        1406,
        314,
        892,
        262,
        717,
        1517,
        314,
        765,
        284,
        466,
        318,
        655,
        651,
        616,
        898,
        1280,
        9552,
        1994,
        11,
        51151
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14179345603301147,
      "compression_ratio": 1.5339366515837105,
      "no_speech_prob": 0.004322201944887638
    },
    {
      "id": 47,
      "seek": 15824,
      "start": 175.28,
      "end": 178.88,
      "text": " then see if I can just get it to run locally.",
      "tokens": [
        51215,
        788,
        766,
        611,
        314,
        460,
        655,
        651,
        340,
        284,
        1057,
        15726,
        13,
        51395
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14179345603301147,
      "compression_ratio": 1.5339366515837105,
      "no_speech_prob": 0.004322201944887638
    },
    {
      "id": 48,
      "seek": 15824,
      "start": 178.88,
      "end": 181.28,
      "text": " Because if I can, great, very happy with that.",
      "tokens": [
        51395,
        4362,
        611,
        314,
        460,
        11,
        1049,
        11,
        845,
        3772,
        351,
        326,
        13,
        51515
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14179345603301147,
      "compression_ratio": 1.5339366515837105,
      "no_speech_prob": 0.004322201944887638
    },
    {
      "id": 49,
      "seek": 15824,
      "start": 181.28,
      "end": 181.78,
      "text": " Let's go.",
      "tokens": [
        51515,
        3914,
        338,
        467,
        13,
        51540
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14179345603301147,
      "compression_ratio": 1.5339366515837105,
      "no_speech_prob": 0.004322201944887638
    },
    {
      "id": 50,
      "seek": 18178,
      "start": 182.42,
      "end": 183.86,
      "text": " Um, however...",
      "tokens": [
        50395,
        21039,
        11,
        2158,
        986,
        50467
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1571979860288907,
      "compression_ratio": 1.5127118644067796,
      "no_speech_prob": 0.019214771687984467
    },
    {
      "id": 51,
      "seek": 18178,
      "start": 186.42,
      "end": 187.54,
      "text": " Oh, yeah, yeah.",
      "tokens": [
        50595,
        3966,
        11,
        10194,
        11,
        10194,
        13,
        50651
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1571979860288907,
      "compression_ratio": 1.5127118644067796,
      "no_speech_prob": 0.019214771687984467
    },
    {
      "id": 52,
      "seek": 18178,
      "start": 187.54,
      "end": 189.62,
      "text": " So if I can get it to run locally, we're very happy.",
      "tokens": [
        50651,
        1406,
        611,
        314,
        460,
        651,
        340,
        284,
        1057,
        15726,
        11,
        356,
        821,
        845,
        3772,
        13,
        50755
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1571979860288907,
      "compression_ratio": 1.5127118644067796,
      "no_speech_prob": 0.019214771687984467
    },
    {
      "id": 53,
      "seek": 18178,
      "start": 190.66,
      "end": 192.18,
      "text": " And we are golden.",
      "tokens": [
        50807,
        843,
        356,
        389,
        10861,
        13,
        50883
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1571979860288907,
      "compression_ratio": 1.5127118644067796,
      "no_speech_prob": 0.019214771687984467
    },
    {
      "id": 54,
      "seek": 18178,
      "start": 192.18,
      "end": 193.94,
      "text": " And then the next thing would be...",
      "tokens": [
        50883,
        843,
        788,
        262,
        1306,
        1517,
        561,
        307,
        986,
        50971
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1571979860288907,
      "compression_ratio": 1.5127118644067796,
      "no_speech_prob": 0.019214771687984467
    },
    {
      "id": 55,
      "seek": 18178,
      "start": 193.94,
      "end": 199.78,
      "text": " Okay, so how do I say instead of going into the open AI key, go into a local LLM?",
      "tokens": [
        50971,
        16805,
        11,
        523,
        703,
        466,
        314,
        910,
        2427,
        286,
        1016,
        656,
        262,
        1280,
        9552,
        1994,
        11,
        467,
        656,
        257,
        1957,
        27140,
        44,
        30,
        51263
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1571979860288907,
      "compression_ratio": 1.5127118644067796,
      "no_speech_prob": 0.019214771687984467
    },
    {
      "id": 56,
      "seek": 18178,
      "start": 200.42000000000002,
      "end": 205.86,
      "text": " And I could do that with like, I guess, kobold or silly tavern or whatever,",
      "tokens": [
        51295,
        843,
        314,
        714,
        466,
        326,
        351,
        588,
        11,
        314,
        4724,
        11,
        479,
        672,
        727,
        393,
        14397,
        42488,
        393,
        4232,
        11,
        51567
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1571979860288907,
      "compression_ratio": 1.5127118644067796,
      "no_speech_prob": 0.019214771687984467
    },
    {
      "id": 57,
      "seek": 18178,
      "start": 205.86,
      "end": 209.3,
      "text": " but it's probably easier to just say it's in Python already.",
      "tokens": [
        51567,
        475,
        340,
        338,
        2192,
        4577,
        284,
        655,
        910,
        340,
        338,
        287,
        11361,
        1541,
        13,
        51739
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1571979860288907,
      "compression_ratio": 1.5127118644067796,
      "no_speech_prob": 0.019214771687984467
    },
    {
      "id": 58,
      "seek": 20930,
      "start": 209.3,
      "end": 216.5,
      "text": " Just get like the hugging face transformers, I think it is, package,",
      "tokens": [
        50363,
        2329,
        651,
        588,
        262,
        46292,
        1986,
        6121,
        364,
        11,
        314,
        892,
        340,
        318,
        11,
        5301,
        11,
        50723
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10588565527224074,
      "compression_ratio": 1.5530973451327434,
      "no_speech_prob": 0.0035833022557199
    },
    {
      "id": 59,
      "seek": 20930,
      "start": 217.54000000000002,
      "end": 221.78,
      "text": " and then use that to get the LLM stuff up and running.",
      "tokens": [
        50775,
        290,
        788,
        779,
        326,
        284,
        651,
        262,
        27140,
        44,
        3404,
        510,
        290,
        2491,
        13,
        50987
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10588565527224074,
      "compression_ratio": 1.5530973451327434,
      "no_speech_prob": 0.0035833022557199
    },
    {
      "id": 60,
      "seek": 20930,
      "start": 222.42000000000002,
      "end": 224.5,
      "text": " Which again, I want to learn how to do anyway,",
      "tokens": [
        51019,
        9022,
        757,
        11,
        314,
        765,
        284,
        2193,
        703,
        284,
        466,
        6949,
        11,
        51123
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10588565527224074,
      "compression_ratio": 1.5530973451327434,
      "no_speech_prob": 0.0035833022557199
    },
    {
      "id": 61,
      "seek": 20930,
      "start": 224.5,
      "end": 229.62,
      "text": " because I want to have a local LLM do summarization and stuff with my notes.",
      "tokens": [
        51123,
        780,
        314,
        765,
        284,
        423,
        257,
        1957,
        27140,
        44,
        466,
        15676,
        1634,
        290,
        3404,
        351,
        616,
        4710,
        13,
        51379
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10588565527224074,
      "compression_ratio": 1.5530973451327434,
      "no_speech_prob": 0.0035833022557199
    },
    {
      "id": 62,
      "seek": 20930,
      "start": 231.14000000000001,
      "end": 232.74,
      "text": " So we'll look into that.",
      "tokens": [
        51455,
        1406,
        356,
        1183,
        804,
        656,
        326,
        13,
        51535
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10588565527224074,
      "compression_ratio": 1.5530973451327434,
      "no_speech_prob": 0.0035833022557199
    },
    {
      "id": 63,
      "seek": 20930,
      "start": 233.94,
      "end": 237.38000000000002,
      "text": " If I can get all of that running on like the eight gigs of VRAM that I've got,",
      "tokens": [
        51595,
        1002,
        314,
        460,
        651,
        477,
        286,
        326,
        2491,
        319,
        588,
        262,
        3624,
        42299,
        286,
        6453,
        2390,
        326,
        314,
        1053,
        1392,
        11,
        51767
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10588565527224074,
      "compression_ratio": 1.5530973451327434,
      "no_speech_prob": 0.0035833022557199
    },
    {
      "id": 64,
      "seek": 23738,
      "start": 237.38,
      "end": 241.46,
      "text": " then that's a really good space to be in, you know?",
      "tokens": [
        50363,
        788,
        326,
        338,
        257,
        1107,
        922,
        2272,
        284,
        307,
        287,
        11,
        345,
        760,
        30,
        50567
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12217848150579778,
      "compression_ratio": 1.6519823788546255,
      "no_speech_prob": 0.0015050866641104221
    },
    {
      "id": 65,
      "seek": 23738,
      "start": 244.18,
      "end": 244.68,
      "text": " Cool.",
      "tokens": [
        50703,
        15226,
        13,
        50728
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12217848150579778,
      "compression_ratio": 1.6519823788546255,
      "no_speech_prob": 0.0015050866641104221
    },
    {
      "id": 66,
      "seek": 23738,
      "start": 245.22,
      "end": 248.34,
      "text": " It looks like their stuff is CPU only at the moment,",
      "tokens": [
        50755,
        632,
        3073,
        588,
        511,
        3404,
        318,
        9135,
        691,
        379,
        262,
        2589,
        11,
        50911
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12217848150579778,
      "compression_ratio": 1.6519823788546255,
      "no_speech_prob": 0.0015050866641104221
    },
    {
      "id": 67,
      "seek": 23738,
      "start": 248.9,
      "end": 253.54,
      "text": " which, I mean, if it runs that fast, CPU only.",
      "tokens": [
        50939,
        543,
        11,
        314,
        1612,
        11,
        611,
        340,
        4539,
        326,
        3049,
        11,
        9135,
        691,
        13,
        51171
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12217848150579778,
      "compression_ratio": 1.6519823788546255,
      "no_speech_prob": 0.0015050866641104221
    },
    {
      "id": 68,
      "seek": 23738,
      "start": 254.57999999999998,
      "end": 257.3,
      "text": " No, if they're using open AI tokens,",
      "tokens": [
        51223,
        1400,
        11,
        611,
        484,
        821,
        1262,
        1280,
        9552,
        16326,
        11,
        51359
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12217848150579778,
      "compression_ratio": 1.6519823788546255,
      "no_speech_prob": 0.0015050866641104221
    },
    {
      "id": 69,
      "seek": 23738,
      "start": 258.1,
      "end": 262.98,
      "text": " then it sounds like they've just got like a set of things that they're working off of.",
      "tokens": [
        51399,
        788,
        340,
        5238,
        588,
        484,
        1053,
        655,
        1392,
        588,
        257,
        900,
        286,
        1243,
        326,
        484,
        821,
        1762,
        572,
        286,
        13,
        51643
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12217848150579778,
      "compression_ratio": 1.6519823788546255,
      "no_speech_prob": 0.0015050866641104221
    },
    {
      "id": 70,
      "seek": 23738,
      "start": 262.98,
      "end": 264.02,
      "text": " And that's why it runs fast,",
      "tokens": [
        51643,
        843,
        326,
        338,
        1521,
        340,
        4539,
        3049,
        11,
        51695
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12217848150579778,
      "compression_ratio": 1.6519823788546255,
      "no_speech_prob": 0.0015050866641104221
    },
    {
      "id": 71,
      "seek": 23738,
      "start": 264.02,
      "end": 266.65999999999997,
      "text": " because they're basically just asking open AI to do it for them.",
      "tokens": [
        51695,
        780,
        484,
        821,
        6209,
        655,
        4737,
        1280,
        9552,
        284,
        466,
        340,
        329,
        606,
        13,
        51827
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12217848150579778,
      "compression_ratio": 1.6519823788546255,
      "no_speech_prob": 0.0015050866641104221
    },
    {
      "id": 72,
      "seek": 26738,
      "start": 267.62,
      "end": 271.46,
      "text": " Um, so yeah, that definitely seems possible.",
      "tokens": [
        50375,
        21039,
        11,
        523,
        10194,
        11,
        326,
        4753,
        2331,
        1744,
        13,
        50567
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13667080320160965,
      "compression_ratio": 1.55,
      "no_speech_prob": 0.0011649602092802525
    },
    {
      "id": 73,
      "seek": 26738,
      "start": 271.46,
      "end": 272.82,
      "text": " And it's interesting for sure.",
      "tokens": [
        50567,
        843,
        340,
        338,
        3499,
        329,
        1654,
        13,
        50635
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13667080320160965,
      "compression_ratio": 1.55,
      "no_speech_prob": 0.0011649602092802525
    },
    {
      "id": 74,
      "seek": 26738,
      "start": 273.86,
      "end": 277.14,
      "text": " Okay, so Nico's asked me to do Julia stuff,",
      "tokens": [
        50687,
        16805,
        11,
        523,
        39360,
        338,
        1965,
        502,
        284,
        466,
        22300,
        3404,
        11,
        50851
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13667080320160965,
      "compression_ratio": 1.55,
      "no_speech_prob": 0.0011649602092802525
    },
    {
      "id": 75,
      "seek": 26738,
      "start": 277.7,
      "end": 280.65999999999997,
      "text": " give a workshop in Julia, which sounds awesome.",
      "tokens": [
        50879,
        1577,
        257,
        20243,
        287,
        22300,
        11,
        543,
        5238,
        7427,
        13,
        51027
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13667080320160965,
      "compression_ratio": 1.55,
      "no_speech_prob": 0.0011649602092802525
    },
    {
      "id": 76,
      "seek": 26738,
      "start": 280.65999999999997,
      "end": 281.62,
      "text": " Very excited for that.",
      "tokens": [
        51027,
        9576,
        6568,
        329,
        326,
        13,
        51075
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13667080320160965,
      "compression_ratio": 1.55,
      "no_speech_prob": 0.0011649602092802525
    },
    {
      "id": 77,
      "seek": 26738,
      "start": 283.3,
      "end": 287.78,
      "text": " I think I really like the idea of this.",
      "tokens": [
        51159,
        314,
        892,
        314,
        1107,
        588,
        262,
        2126,
        286,
        428,
        13,
        51383
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13667080320160965,
      "compression_ratio": 1.55,
      "no_speech_prob": 0.0011649602092802525
    },
    {
      "id": 78,
      "seek": 26738,
      "start": 287.78,
      "end": 290.74,
      "text": " So I think what I need to do is create a Google form or something,",
      "tokens": [
        51383,
        1406,
        314,
        892,
        644,
        314,
        761,
        284,
        466,
        318,
        2251,
        257,
        3012,
        1296,
        393,
        1223,
        11,
        51531
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13667080320160965,
      "compression_ratio": 1.55,
      "no_speech_prob": 0.0011649602092802525
    },
    {
      "id": 79,
      "seek": 26738,
      "start": 291.3,
      "end": 293.3,
      "text": " which basically asks, you know,",
      "tokens": [
        51559,
        543,
        6209,
        7893,
        11,
        345,
        760,
        11,
        51659
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13667080320160965,
      "compression_ratio": 1.55,
      "no_speech_prob": 0.0011649602092802525
    },
    {
      "id": 80,
      "seek": 26738,
      "start": 294.34,
      "end": 295.78,
      "text": " well, what are the questions it would ask?",
      "tokens": [
        51711,
        880,
        11,
        644,
        389,
        262,
        2683,
        340,
        561,
        1265,
        30,
        51783
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13667080320160965,
      "compression_ratio": 1.55,
      "no_speech_prob": 0.0011649602092802525
    },
    {
      "id": 81,
      "seek": 26738,
      "start": 295.78,
      "end": 296.98,
      "text": " What language do you write in?",
      "tokens": [
        51783,
        1867,
        3303,
        466,
        345,
        3551,
        287,
        30,
        51843
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13667080320160965,
      "compression_ratio": 1.55,
      "no_speech_prob": 0.0011649602092802525
    },
    {
      "id": 82,
      "seek": 29698,
      "start": 297.14000000000004,
      "end": 299.14000000000004,
      "text": " Obviously, Python's going to be an option,",
      "tokens": [
        50371,
        16263,
        11,
        11361,
        338,
        1016,
        284,
        307,
        281,
        3038,
        11,
        50471
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1616896209716797,
      "compression_ratio": 1.60352422907489,
      "no_speech_prob": 0.03097498044371605
    },
    {
      "id": 83,
      "seek": 29698,
      "start": 299.14000000000004,
      "end": 303.06,
      "text": " and we'll get some of the other key players,",
      "tokens": [
        50471,
        290,
        356,
        1183,
        651,
        617,
        286,
        262,
        584,
        1994,
        1938,
        11,
        50667
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1616896209716797,
      "compression_ratio": 1.60352422907489,
      "no_speech_prob": 0.03097498044371605
    },
    {
      "id": 84,
      "seek": 29698,
      "start": 303.06,
      "end": 305.06,
      "text": " R, you know, C, C++.",
      "tokens": [
        50667,
        371,
        11,
        345,
        760,
        11,
        327,
        11,
        327,
        4880,
        13,
        50767
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1616896209716797,
      "compression_ratio": 1.60352422907489,
      "no_speech_prob": 0.03097498044371605
    },
    {
      "id": 85,
      "seek": 29698,
      "start": 307.70000000000005,
      "end": 310.42,
      "text": " We'll get, what's the other big one?",
      "tokens": [
        50899,
        775,
        1183,
        651,
        11,
        644,
        338,
        262,
        584,
        1263,
        530,
        30,
        51035
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1616896209716797,
      "compression_ratio": 1.60352422907489,
      "no_speech_prob": 0.03097498044371605
    },
    {
      "id": 86,
      "seek": 29698,
      "start": 311.14000000000004,
      "end": 311.62,
      "text": " Rust.",
      "tokens": [
        51071,
        17103,
        13,
        51095
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1616896209716797,
      "compression_ratio": 1.60352422907489,
      "no_speech_prob": 0.03097498044371605
    },
    {
      "id": 87,
      "seek": 29698,
      "start": 311.62,
      "end": 313.14000000000004,
      "text": " Yeah, we'll get all those ones, right?",
      "tokens": [
        51095,
        9425,
        11,
        356,
        1183,
        651,
        477,
        883,
        3392,
        11,
        826,
        30,
        51171
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1616896209716797,
      "compression_ratio": 1.60352422907489,
      "no_speech_prob": 0.03097498044371605
    },
    {
      "id": 88,
      "seek": 29698,
      "start": 313.14000000000004,
      "end": 315.22,
      "text": " I'll put Julia in there, just in case.",
      "tokens": [
        51171,
        314,
        1183,
        1234,
        22300,
        287,
        612,
        11,
        655,
        287,
        1339,
        13,
        51275
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1616896209716797,
      "compression_ratio": 1.60352422907489,
      "no_speech_prob": 0.03097498044371605
    },
    {
      "id": 89,
      "seek": 29698,
      "start": 315.22,
      "end": 315.86,
      "text": " That'll be fun.",
      "tokens": [
        51275,
        1320,
        1183,
        307,
        1257,
        13,
        51307
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1616896209716797,
      "compression_ratio": 1.60352422907489,
      "no_speech_prob": 0.03097498044371605
    },
    {
      "id": 90,
      "seek": 29698,
      "start": 317.22,
      "end": 320.5,
      "text": " And then, you know, what do you do with your code, right?",
      "tokens": [
        51375,
        843,
        788,
        11,
        345,
        760,
        11,
        644,
        466,
        345,
        466,
        351,
        534,
        2438,
        11,
        826,
        30,
        51539
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1616896209716797,
      "compression_ratio": 1.60352422907489,
      "no_speech_prob": 0.03097498044371605
    },
    {
      "id": 91,
      "seek": 29698,
      "start": 320.5,
      "end": 322.02000000000004,
      "text": " Is another question.",
      "tokens": [
        51539,
        1148,
        1194,
        1808,
        13,
        51615
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1616896209716797,
      "compression_ratio": 1.60352422907489,
      "no_speech_prob": 0.03097498044371605
    },
    {
      "id": 92,
      "seek": 29698,
      "start": 322.02000000000004,
      "end": 324.42,
      "text": " So like, some options I'll put in there",
      "tokens": [
        51615,
        1406,
        588,
        11,
        617,
        3689,
        314,
        1183,
        1234,
        287,
        612,
        51735
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1616896209716797,
      "compression_ratio": 1.60352422907489,
      "no_speech_prob": 0.03097498044371605
    },
    {
      "id": 93,
      "seek": 32442,
      "start": 325.38,
      "end": 328.1,
      "text": " would be something like write, you know,",
      "tokens": [
        50411,
        561,
        307,
        1223,
        588,
        3551,
        11,
        345,
        760,
        11,
        50547
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09739581021395596,
      "compression_ratio": 1.5842105263157895,
      "no_speech_prob": 0.003930194303393364
    },
    {
      "id": 94,
      "seek": 32442,
      "start": 328.1,
      "end": 330.26,
      "text": " quick and dirty scripts would be one.",
      "tokens": [
        50547,
        2068,
        290,
        11841,
        14750,
        561,
        307,
        530,
        13,
        50655
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09739581021395596,
      "compression_ratio": 1.5842105263157895,
      "no_speech_prob": 0.003930194303393364
    },
    {
      "id": 95,
      "seek": 32442,
      "start": 331.06,
      "end": 336.74,
      "text": " I would say write programs for me to use,",
      "tokens": [
        50695,
        314,
        561,
        910,
        3551,
        4056,
        329,
        502,
        284,
        779,
        11,
        50979
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09739581021395596,
      "compression_ratio": 1.5842105263157895,
      "no_speech_prob": 0.003930194303393364
    },
    {
      "id": 96,
      "seek": 32442,
      "start": 338.42,
      "end": 341.46000000000004,
      "text": " write programs for others to use,",
      "tokens": [
        51063,
        3551,
        4056,
        329,
        1854,
        284,
        779,
        11,
        51215
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09739581021395596,
      "compression_ratio": 1.5842105263157895,
      "no_speech_prob": 0.003930194303393364
    },
    {
      "id": 97,
      "seek": 32442,
      "start": 341.46000000000004,
      "end": 343.86,
      "text": " write packages to distribute, right?",
      "tokens": [
        51215,
        3551,
        10392,
        284,
        14983,
        11,
        826,
        30,
        51335
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09739581021395596,
      "compression_ratio": 1.5842105263157895,
      "no_speech_prob": 0.003930194303393364
    },
    {
      "id": 98,
      "seek": 32442,
      "start": 343.86,
      "end": 344.66,
      "text": " That's the kind of thing.",
      "tokens": [
        51335,
        1320,
        338,
        262,
        1611,
        286,
        1517,
        13,
        51375
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09739581021395596,
      "compression_ratio": 1.5842105263157895,
      "no_speech_prob": 0.003930194303393364
    },
    {
      "id": 99,
      "seek": 32442,
      "start": 345.54,
      "end": 347.38,
      "text": " And then there'll be questions of like,",
      "tokens": [
        51419,
        843,
        788,
        612,
        1183,
        307,
        2683,
        286,
        588,
        11,
        51511
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09739581021395596,
      "compression_ratio": 1.5842105263157895,
      "no_speech_prob": 0.003930194303393364
    },
    {
      "id": 100,
      "seek": 32442,
      "start": 347.38,
      "end": 350.66,
      "text": " okay, well, in what space, how do you code?",
      "tokens": [
        51511,
        8788,
        11,
        880,
        11,
        287,
        644,
        2272,
        11,
        703,
        466,
        345,
        2438,
        30,
        51675
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09739581021395596,
      "compression_ratio": 1.5842105263157895,
      "no_speech_prob": 0.003930194303393364
    },
    {
      "id": 101,
      "seek": 35066,
      "start": 350.66,
      "end": 354.74,
      "text": " So this would be like, you know, I code in a GUI,",
      "tokens": [
        50363,
        1406,
        428,
        561,
        307,
        588,
        11,
        345,
        760,
        11,
        314,
        2438,
        287,
        257,
        25757,
        11,
        50567
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13819445460295873,
      "compression_ratio": 1.6465116279069767,
      "no_speech_prob": 0.005806653294712305
    },
    {
      "id": 102,
      "seek": 35066,
      "start": 356.02000000000004,
      "end": 357.06,
      "text": " VS code, whatever.",
      "tokens": [
        50631,
        22269,
        2438,
        11,
        4232,
        13,
        50683
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13819445460295873,
      "compression_ratio": 1.6465116279069767,
      "no_speech_prob": 0.005806653294712305
    },
    {
      "id": 103,
      "seek": 35066,
      "start": 358.18,
      "end": 360.02000000000004,
      "text": " Like, oh, sorry, I code in a project,",
      "tokens": [
        50739,
        4525,
        11,
        11752,
        11,
        7926,
        11,
        314,
        2438,
        287,
        257,
        1628,
        11,
        50831
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13819445460295873,
      "compression_ratio": 1.6465116279069767,
      "no_speech_prob": 0.005806653294712305
    },
    {
      "id": 104,
      "seek": 35066,
      "start": 360.02000000000004,
      "end": 361.86,
      "text": " C, VS code, whatever.",
      "tokens": [
        50831,
        327,
        11,
        22269,
        2438,
        11,
        4232,
        13,
        50923
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13819445460295873,
      "compression_ratio": 1.6465116279069767,
      "no_speech_prob": 0.005806653294712305
    },
    {
      "id": 105,
      "seek": 35066,
      "start": 361.86,
      "end": 364.58000000000004,
      "text": " I code in a notebook, like Jupyter notebook.",
      "tokens": [
        50923,
        314,
        2438,
        287,
        257,
        20922,
        11,
        588,
        449,
        929,
        88,
        353,
        20922,
        13,
        51059
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13819445460295873,
      "compression_ratio": 1.6465116279069767,
      "no_speech_prob": 0.005806653294712305
    },
    {
      "id": 106,
      "seek": 35066,
      "start": 365.14000000000004,
      "end": 366.02000000000004,
      "text": " I code locally.",
      "tokens": [
        51087,
        314,
        2438,
        15726,
        13,
        51131
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13819445460295873,
      "compression_ratio": 1.6465116279069767,
      "no_speech_prob": 0.005806653294712305
    },
    {
      "id": 107,
      "seek": 35066,
      "start": 366.02000000000004,
      "end": 367.22,
      "text": " I code on a server.",
      "tokens": [
        51131,
        314,
        2438,
        319,
        257,
        4382,
        13,
        51191
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13819445460295873,
      "compression_ratio": 1.6465116279069767,
      "no_speech_prob": 0.005806653294712305
    },
    {
      "id": 108,
      "seek": 35066,
      "start": 367.22,
      "end": 368.34000000000003,
      "text": " All these kinds of questions.",
      "tokens": [
        51191,
        1439,
        777,
        6982,
        286,
        2683,
        13,
        51247
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13819445460295873,
      "compression_ratio": 1.6465116279069767,
      "no_speech_prob": 0.005806653294712305
    },
    {
      "id": 109,
      "seek": 35066,
      "start": 369.38,
      "end": 373.14000000000004,
      "text": " And just get an idea of how people do computing in Stromlo.",
      "tokens": [
        51299,
        843,
        655,
        651,
        281,
        2126,
        286,
        703,
        661,
        466,
        14492,
        287,
        520,
        398,
        5439,
        13,
        51487
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13819445460295873,
      "compression_ratio": 1.6465116279069767,
      "no_speech_prob": 0.005806653294712305
    },
    {
      "id": 110,
      "seek": 35066,
      "start": 373.94000000000005,
      "end": 375.3,
      "text": " I think would be very useful.",
      "tokens": [
        51527,
        314,
        892,
        561,
        307,
        845,
        4465,
        13,
        51595
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13819445460295873,
      "compression_ratio": 1.6465116279069767,
      "no_speech_prob": 0.005806653294712305
    },
    {
      "id": 111,
      "seek": 35066,
      "start": 376.98,
      "end": 378.26000000000005,
      "text": " Yeah, I agree with that.",
      "tokens": [
        51679,
        9425,
        11,
        314,
        4236,
        351,
        326,
        13,
        51743
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13819445460295873,
      "compression_ratio": 1.6465116279069767,
      "no_speech_prob": 0.005806653294712305
    },
    {
      "id": 112,
      "seek": 37826,
      "start": 378.65999999999997,
      "end": 383.46,
      "text": " And then get some basic instructions for like,",
      "tokens": [
        50383,
        843,
        788,
        651,
        617,
        4096,
        7729,
        329,
        588,
        11,
        50623
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10244219771055417,
      "compression_ratio": 1.635135135135135,
      "no_speech_prob": 0.0041838339529931545
    },
    {
      "id": 113,
      "seek": 37826,
      "start": 384.02,
      "end": 385.94,
      "text": " how do you get Julia up and running",
      "tokens": [
        50651,
        703,
        466,
        345,
        651,
        22300,
        510,
        290,
        2491,
        50747
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10244219771055417,
      "compression_ratio": 1.635135135135135,
      "no_speech_prob": 0.0041838339529931545
    },
    {
      "id": 114,
      "seek": 37826,
      "start": 386.5,
      "end": 390.65999999999997,
      "text": " on whatever device you're on, right?",
      "tokens": [
        50775,
        319,
        4232,
        3335,
        345,
        821,
        319,
        11,
        826,
        30,
        50983
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10244219771055417,
      "compression_ratio": 1.635135135135135,
      "no_speech_prob": 0.0041838339529931545
    },
    {
      "id": 115,
      "seek": 37826,
      "start": 391.21999999999997,
      "end": 393.06,
      "text": " And basically what I want them to have",
      "tokens": [
        51011,
        843,
        6209,
        644,
        314,
        765,
        606,
        284,
        423,
        51103
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10244219771055417,
      "compression_ratio": 1.635135135135135,
      "no_speech_prob": 0.0041838339529931545
    },
    {
      "id": 116,
      "seek": 37826,
      "start": 393.06,
      "end": 396.34,
      "text": " is a directory with a project.toml in it.",
      "tokens": [
        51103,
        318,
        257,
        8619,
        351,
        257,
        1628,
        13,
        39532,
        75,
        287,
        340,
        13,
        51267
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10244219771055417,
      "compression_ratio": 1.635135135135135,
      "no_speech_prob": 0.0041838339529931545
    },
    {
      "id": 117,
      "seek": 37826,
      "start": 396.34,
      "end": 397.14,
      "text": " And that's about it.",
      "tokens": [
        51267,
        843,
        326,
        338,
        546,
        340,
        13,
        51307
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10244219771055417,
      "compression_ratio": 1.635135135135135,
      "no_speech_prob": 0.0041838339529931545
    },
    {
      "id": 118,
      "seek": 37826,
      "start": 399.78,
      "end": 401.86,
      "text": " And that'll be good for them to have to start up.",
      "tokens": [
        51439,
        843,
        326,
        1183,
        307,
        922,
        329,
        606,
        284,
        423,
        284,
        923,
        510,
        13,
        51543
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10244219771055417,
      "compression_ratio": 1.635135135135135,
      "no_speech_prob": 0.0041838339529931545
    },
    {
      "id": 119,
      "seek": 37826,
      "start": 402.65999999999997,
      "end": 404.58,
      "text": " If they've got that, we're happy, we're golden.",
      "tokens": [
        51583,
        1002,
        484,
        1053,
        1392,
        326,
        11,
        356,
        821,
        3772,
        11,
        356,
        821,
        10861,
        13,
        51679
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10244219771055417,
      "compression_ratio": 1.635135135135135,
      "no_speech_prob": 0.0041838339529931545
    },
    {
      "id": 120,
      "seek": 37826,
      "start": 406.09999999999997,
      "end": 407.7,
      "text": " And then the things I actually want to show",
      "tokens": [
        51755,
        843,
        788,
        262,
        1243,
        314,
        1682,
        765,
        284,
        905,
        51835
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10244219771055417,
      "compression_ratio": 1.635135135135135,
      "no_speech_prob": 0.0041838339529931545
    },
    {
      "id": 121,
      "seek": 40826,
      "start": 409.21999999999997,
      "end": 411.94,
      "text": " So why should someone use Julia?",
      "tokens": [
        50411,
        1406,
        1521,
        815,
        2130,
        779,
        22300,
        30,
        50547
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12702729728784454,
      "compression_ratio": 1.706806282722513,
      "no_speech_prob": 0.0024390167091041803
    },
    {
      "id": 122,
      "seek": 40826,
      "start": 412.58,
      "end": 414.26,
      "text": " I really like the idea of titling the talk",
      "tokens": [
        50579,
        314,
        1107,
        588,
        262,
        2126,
        286,
        5259,
        1359,
        262,
        1561,
        50663
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12702729728784454,
      "compression_ratio": 1.706806282722513,
      "no_speech_prob": 0.0024390167091041803
    },
    {
      "id": 123,
      "seek": 40826,
      "start": 414.26,
      "end": 417.06,
      "text": " why I use Julia and you probably shouldn't.",
      "tokens": [
        50663,
        1521,
        314,
        779,
        22300,
        290,
        345,
        2192,
        6584,
        470,
        13,
        50803
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12702729728784454,
      "compression_ratio": 1.706806282722513,
      "no_speech_prob": 0.0024390167091041803
    },
    {
      "id": 124,
      "seek": 40826,
      "start": 417.06,
      "end": 418.74,
      "text": " I think that's a great, great talk title.",
      "tokens": [
        50803,
        314,
        892,
        326,
        338,
        257,
        1049,
        11,
        1049,
        1561,
        3670,
        13,
        50887
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12702729728784454,
      "compression_ratio": 1.706806282722513,
      "no_speech_prob": 0.0024390167091041803
    },
    {
      "id": 125,
      "seek": 40826,
      "start": 419.62,
      "end": 422.65999999999997,
      "text": " Because I think within astronomy,",
      "tokens": [
        50931,
        4362,
        314,
        892,
        1626,
        37145,
        11,
        51083
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12702729728784454,
      "compression_ratio": 1.706806282722513,
      "no_speech_prob": 0.0024390167091041803
    },
    {
      "id": 126,
      "seek": 40826,
      "start": 423.94,
      "end": 428.34,
      "text": " there are a few spaces where Julia has really,",
      "tokens": [
        51147,
        612,
        389,
        257,
        1178,
        9029,
        810,
        22300,
        468,
        1107,
        11,
        51367
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12702729728784454,
      "compression_ratio": 1.706806282722513,
      "no_speech_prob": 0.0024390167091041803
    },
    {
      "id": 127,
      "seek": 40826,
      "start": 428.34,
      "end": 430.09999999999997,
      "text": " is going to be really, really useful.",
      "tokens": [
        51367,
        318,
        1016,
        284,
        307,
        1107,
        11,
        1107,
        4465,
        13,
        51455
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12702729728784454,
      "compression_ratio": 1.706806282722513,
      "no_speech_prob": 0.0024390167091041803
    },
    {
      "id": 128,
      "seek": 40826,
      "start": 432.98,
      "end": 436.34,
      "text": " But I think the issue in astronomy especially",
      "tokens": [
        51599,
        887,
        314,
        892,
        262,
        2071,
        287,
        37145,
        2592,
        51767
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12702729728784454,
      "compression_ratio": 1.706806282722513,
      "no_speech_prob": 0.0024390167091041803
    },
    {
      "id": 129,
      "seek": 43634,
      "start": 436.41999999999996,
      "end": 439.14,
      "text": " is that so much of the work we do",
      "tokens": [
        50367,
        318,
        326,
        523,
        881,
        286,
        262,
        670,
        356,
        466,
        50503
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09908034883696458,
      "compression_ratio": 1.6077586206896552,
      "no_speech_prob": 0.00165948283392936
    },
    {
      "id": 130,
      "seek": 43634,
      "start": 439.14,
      "end": 444.09999999999997,
      "text": " is going to be associated with a very specific thing, right?",
      "tokens": [
        50503,
        318,
        1016,
        284,
        307,
        3917,
        351,
        257,
        845,
        2176,
        1517,
        11,
        826,
        30,
        50751
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09908034883696458,
      "compression_ratio": 1.6077586206896552,
      "no_speech_prob": 0.00165948283392936
    },
    {
      "id": 131,
      "seek": 43634,
      "start": 444.09999999999997,
      "end": 446.17999999999995,
      "text": " As in like, if I look at DBAS,",
      "tokens": [
        50751,
        1081,
        287,
        588,
        11,
        611,
        314,
        804,
        379,
        20137,
        1921,
        11,
        50855
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09908034883696458,
      "compression_ratio": 1.6077586206896552,
      "no_speech_prob": 0.00165948283392936
    },
    {
      "id": 132,
      "seek": 43634,
      "start": 447.06,
      "end": 449.06,
      "text": " Julia is not going to come into DBAS, right?",
      "tokens": [
        50899,
        22300,
        318,
        407,
        1016,
        284,
        1282,
        656,
        20137,
        1921,
        11,
        826,
        30,
        50999
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09908034883696458,
      "compression_ratio": 1.6077586206896552,
      "no_speech_prob": 0.00165948283392936
    },
    {
      "id": 133,
      "seek": 43634,
      "start": 449.06,
      "end": 451.94,
      "text": " I could use it instead of Django,",
      "tokens": [
        50999,
        314,
        714,
        779,
        340,
        2427,
        286,
        37770,
        11,
        51143
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09908034883696458,
      "compression_ratio": 1.6077586206896552,
      "no_speech_prob": 0.00165948283392936
    },
    {
      "id": 134,
      "seek": 43634,
      "start": 451.94,
      "end": 453.53999999999996,
      "text": " but Django is already set up for that.",
      "tokens": [
        51143,
        475,
        37770,
        318,
        1541,
        900,
        510,
        329,
        326,
        13,
        51223
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09908034883696458,
      "compression_ratio": 1.6077586206896552,
      "no_speech_prob": 0.00165948283392936
    },
    {
      "id": 135,
      "seek": 43634,
      "start": 454.09999999999997,
      "end": 456.9,
      "text": " We have PyWives, which obviously is a Python interface.",
      "tokens": [
        51251,
        775,
        423,
        9485,
        54,
        1083,
        11,
        543,
        6189,
        318,
        257,
        11361,
        7071,
        13,
        51391
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09908034883696458,
      "compression_ratio": 1.6077586206896552,
      "no_speech_prob": 0.00165948283392936
    },
    {
      "id": 136,
      "seek": 43634,
      "start": 458.09999999999997,
      "end": 460.5,
      "text": " So I could use it for that, but we don't need to.",
      "tokens": [
        51451,
        1406,
        314,
        714,
        779,
        340,
        329,
        326,
        11,
        475,
        356,
        836,
        470,
        761,
        284,
        13,
        51571
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09908034883696458,
      "compression_ratio": 1.6077586206896552,
      "no_speech_prob": 0.00165948283392936
    },
    {
      "id": 137,
      "seek": 43634,
      "start": 460.5,
      "end": 461.29999999999995,
      "text": " We've already got that.",
      "tokens": [
        51571,
        775,
        1053,
        1541,
        1392,
        326,
        13,
        51611
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09908034883696458,
      "compression_ratio": 1.6077586206896552,
      "no_speech_prob": 0.00165948283392936
    },
    {
      "id": 138,
      "seek": 46130,
      "start": 461.62,
      "end": 466.34000000000003,
      "text": " I think Julia for an astronomer is most useful",
      "tokens": [
        50379,
        314,
        892,
        22300,
        329,
        281,
        47603,
        318,
        749,
        4465,
        50615
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13224653265942102,
      "compression_ratio": 1.5906735751295338,
      "no_speech_prob": 0.02579832635819912
    },
    {
      "id": 139,
      "seek": 46130,
      "start": 466.98,
      "end": 469.38,
      "text": " if the astronomer is writing code.",
      "tokens": [
        50647,
        611,
        262,
        47603,
        318,
        3597,
        2438,
        13,
        50767
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13224653265942102,
      "compression_ratio": 1.5906735751295338,
      "no_speech_prob": 0.02579832635819912
    },
    {
      "id": 140,
      "seek": 46130,
      "start": 471.06,
      "end": 474.5,
      "text": " And specifically, I think it's going to be most useful",
      "tokens": [
        50851,
        843,
        5734,
        11,
        314,
        892,
        340,
        338,
        1016,
        284,
        307,
        749,
        4465,
        51023
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13224653265942102,
      "compression_ratio": 1.5906735751295338,
      "no_speech_prob": 0.02579832635819912
    },
    {
      "id": 141,
      "seek": 46130,
      "start": 474.5,
      "end": 476.18,
      "text": " if you're writing code for others to use.",
      "tokens": [
        51023,
        611,
        345,
        821,
        3597,
        2438,
        329,
        1854,
        284,
        779,
        13,
        51107
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13224653265942102,
      "compression_ratio": 1.5906735751295338,
      "no_speech_prob": 0.02579832635819912
    },
    {
      "id": 142,
      "seek": 46130,
      "start": 479.3,
      "end": 481.62,
      "text": " Yeah, so that's a good way of doing it.",
      "tokens": [
        51263,
        9425,
        11,
        523,
        326,
        338,
        257,
        922,
        835,
        286,
        1804,
        340,
        13,
        51379
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13224653265942102,
      "compression_ratio": 1.5906735751295338,
      "no_speech_prob": 0.02579832635819912
    },
    {
      "id": 143,
      "seek": 46130,
      "start": 481.62,
      "end": 487.06,
      "text": " I might kind of do it as different sizes of whatever, right?",
      "tokens": [
        51379,
        314,
        1244,
        1611,
        286,
        466,
        340,
        355,
        1180,
        10620,
        286,
        4232,
        11,
        826,
        30,
        51651
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13224653265942102,
      "compression_ratio": 1.5906735751295338,
      "no_speech_prob": 0.02579832635819912
    },
    {
      "id": 144,
      "seek": 46130,
      "start": 487.94,
      "end": 488.98,
      "text": " So I'll say something like,",
      "tokens": [
        51695,
        1406,
        314,
        1183,
        910,
        1223,
        588,
        11,
        51747
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13224653265942102,
      "compression_ratio": 1.5906735751295338,
      "no_speech_prob": 0.02579832635819912
    },
    {
      "id": 145,
      "seek": 48898,
      "start": 489.78000000000003,
      "end": 492.1,
      "text": " you know, if what you do is you use Python",
      "tokens": [
        50403,
        345,
        760,
        11,
        611,
        644,
        345,
        466,
        318,
        345,
        779,
        11361,
        50519
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07640578334492848,
      "compression_ratio": 1.9728682170542635,
      "no_speech_prob": 0.009625814855098724
    },
    {
      "id": 146,
      "seek": 48898,
      "start": 492.1,
      "end": 493.54,
      "text": " to create quick and dirty scripts,",
      "tokens": [
        50519,
        284,
        2251,
        2068,
        290,
        11841,
        14750,
        11,
        50591
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07640578334492848,
      "compression_ratio": 1.9728682170542635,
      "no_speech_prob": 0.009625814855098724
    },
    {
      "id": 147,
      "seek": 48898,
      "start": 494.1,
      "end": 496.98,
      "text": " here's Julia being used for quick and dirty scripts, you know?",
      "tokens": [
        50619,
        994,
        338,
        22300,
        852,
        973,
        329,
        2068,
        290,
        11841,
        14750,
        11,
        345,
        760,
        30,
        50763
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07640578334492848,
      "compression_ratio": 1.9728682170542635,
      "no_speech_prob": 0.009625814855098724
    },
    {
      "id": 148,
      "seek": 48898,
      "start": 497.62,
      "end": 498.74,
      "text": " So this would be something like,",
      "tokens": [
        50795,
        1406,
        428,
        561,
        307,
        1223,
        588,
        11,
        50851
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07640578334492848,
      "compression_ratio": 1.9728682170542635,
      "no_speech_prob": 0.009625814855098724
    },
    {
      "id": 149,
      "seek": 48898,
      "start": 498.74,
      "end": 500.58000000000004,
      "text": " you know, what do you get for free",
      "tokens": [
        50851,
        345,
        760,
        11,
        644,
        466,
        345,
        651,
        329,
        1479,
        50943
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07640578334492848,
      "compression_ratio": 1.9728682170542635,
      "no_speech_prob": 0.009625814855098724
    },
    {
      "id": 150,
      "seek": 48898,
      "start": 500.58000000000004,
      "end": 503.3,
      "text": " if you use Julia for quick and dirty scripts instead of Python?",
      "tokens": [
        50943,
        611,
        345,
        779,
        22300,
        329,
        2068,
        290,
        11841,
        14750,
        2427,
        286,
        11361,
        30,
        51079
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07640578334492848,
      "compression_ratio": 1.9728682170542635,
      "no_speech_prob": 0.009625814855098724
    },
    {
      "id": 151,
      "seek": 48898,
      "start": 503.3,
      "end": 505.14000000000004,
      "text": " Well, the kindest thing you get for free",
      "tokens": [
        51079,
        3894,
        11,
        262,
        1611,
        395,
        1517,
        345,
        651,
        329,
        1479,
        51171
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07640578334492848,
      "compression_ratio": 1.9728682170542635,
      "no_speech_prob": 0.009625814855098724
    },
    {
      "id": 152,
      "seek": 48898,
      "start": 505.14000000000004,
      "end": 506.98,
      "text": " is you get package management for free",
      "tokens": [
        51171,
        318,
        345,
        651,
        5301,
        4542,
        329,
        1479,
        51263
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07640578334492848,
      "compression_ratio": 1.9728682170542635,
      "no_speech_prob": 0.009625814855098724
    },
    {
      "id": 153,
      "seek": 48898,
      "start": 506.98,
      "end": 510.5,
      "text": " without having to worry about which conda environment,",
      "tokens": [
        51263,
        1231,
        1719,
        284,
        5490,
        546,
        543,
        1779,
        64,
        2858,
        11,
        51439
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07640578334492848,
      "compression_ratio": 1.9728682170542635,
      "no_speech_prob": 0.009625814855098724
    },
    {
      "id": 154,
      "seek": 48898,
      "start": 510.5,
      "end": 511.3,
      "text": " whatever you're using.",
      "tokens": [
        51439,
        4232,
        345,
        821,
        1262,
        13,
        51479
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07640578334492848,
      "compression_ratio": 1.9728682170542635,
      "no_speech_prob": 0.009625814855098724
    },
    {
      "id": 155,
      "seek": 48898,
      "start": 513.14,
      "end": 515.54,
      "text": " Your quick and dirty script can be",
      "tokens": [
        51571,
        3406,
        2068,
        290,
        11841,
        4226,
        460,
        307,
        51691
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07640578334492848,
      "compression_ratio": 1.9728682170542635,
      "no_speech_prob": 0.009625814855098724
    },
    {
      "id": 156,
      "seek": 48898,
      "start": 516.4200000000001,
      "end": 518.5,
      "text": " slightly less quick and dirty quite easily.",
      "tokens": [
        51735,
        4622,
        1342,
        2068,
        290,
        11841,
        2407,
        3538,
        13,
        51839
      ],
      "temperature": 0.0,
      "avg_logprob": -0.07640578334492848,
      "compression_ratio": 1.9728682170542635,
      "no_speech_prob": 0.009625814855098724
    },
    {
      "id": 157,
      "seek": 51898,
      "start": 519.0600000000001,
      "end": 519.7,
      "text": " For instance,",
      "tokens": [
        50367,
        1114,
        4554,
        11,
        50399
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10463572937308006,
      "compression_ratio": 1.6333333333333333,
      "no_speech_prob": 0.002152232686057687
    },
    {
      "id": 158,
      "seek": 51898,
      "start": 522.26,
      "end": 524.58,
      "text": " yeah, it's just so much of it is like",
      "tokens": [
        50527,
        10194,
        11,
        340,
        338,
        655,
        523,
        881,
        286,
        340,
        318,
        588,
        50643
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10463572937308006,
      "compression_ratio": 1.6333333333333333,
      "no_speech_prob": 0.002152232686057687
    },
    {
      "id": 159,
      "seek": 51898,
      "start": 524.58,
      "end": 526.74,
      "text": " the IO side of things is the slow part.",
      "tokens": [
        50643,
        262,
        24418,
        1735,
        286,
        1243,
        318,
        262,
        3105,
        636,
        13,
        50751
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10463572937308006,
      "compression_ratio": 1.6333333333333333,
      "no_speech_prob": 0.002152232686057687
    },
    {
      "id": 160,
      "seek": 51898,
      "start": 528.4200000000001,
      "end": 530.82,
      "text": " Because you wouldn't want plotting",
      "tokens": [
        50835,
        4362,
        345,
        3636,
        470,
        765,
        29353,
        50955
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10463572937308006,
      "compression_ratio": 1.6333333333333333,
      "no_speech_prob": 0.002152232686057687
    },
    {
      "id": 161,
      "seek": 51898,
      "start": 530.82,
      "end": 533.22,
      "text": " as a quick and dirty thing in Julia, right?",
      "tokens": [
        50955,
        355,
        257,
        2068,
        290,
        11841,
        1517,
        287,
        22300,
        11,
        826,
        30,
        51075
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10463572937308006,
      "compression_ratio": 1.6333333333333333,
      "no_speech_prob": 0.002152232686057687
    },
    {
      "id": 162,
      "seek": 51898,
      "start": 533.22,
      "end": 534.9,
      "text": " That's not going to work out.",
      "tokens": [
        51075,
        1320,
        338,
        407,
        1016,
        284,
        670,
        503,
        13,
        51159
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10463572937308006,
      "compression_ratio": 1.6333333333333333,
      "no_speech_prob": 0.002152232686057687
    },
    {
      "id": 163,
      "seek": 51898,
      "start": 535.7,
      "end": 538.74,
      "text": " So what are quick and dirty things",
      "tokens": [
        51199,
        1406,
        644,
        389,
        2068,
        290,
        11841,
        1243,
        51351
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10463572937308006,
      "compression_ratio": 1.6333333333333333,
      "no_speech_prob": 0.002152232686057687
    },
    {
      "id": 164,
      "seek": 51898,
      "start": 538.74,
      "end": 541.38,
      "text": " that people do in Python right now?",
      "tokens": [
        51351,
        326,
        661,
        466,
        287,
        11361,
        826,
        783,
        30,
        51483
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10463572937308006,
      "compression_ratio": 1.6333333333333333,
      "no_speech_prob": 0.002152232686057687
    },
    {
      "id": 165,
      "seek": 51898,
      "start": 543.22,
      "end": 545.78,
      "text": " Okay, so one thought that I had is",
      "tokens": [
        51575,
        16805,
        11,
        523,
        530,
        1807,
        326,
        314,
        550,
        318,
        51703
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10463572937308006,
      "compression_ratio": 1.6333333333333333,
      "no_speech_prob": 0.002152232686057687
    },
    {
      "id": 166,
      "seek": 51898,
      "start": 546.74,
      "end": 548.26,
      "text": " a quick and dirty thing you could do",
      "tokens": [
        51751,
        257,
        2068,
        290,
        11841,
        1517,
        345,
        714,
        466,
        51827
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10463572937308006,
      "compression_ratio": 1.6333333333333333,
      "no_speech_prob": 0.002152232686057687
    },
    {
      "id": 167,
      "seek": 54826,
      "start": 548.26,
      "end": 549.7,
      "text": " is you've got data of some type",
      "tokens": [
        50363,
        318,
        345,
        1053,
        1392,
        1366,
        286,
        617,
        2099,
        50435
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06705775468245796,
      "compression_ratio": 1.7932330827067668,
      "no_speech_prob": 0.0012851693900302052
    },
    {
      "id": 168,
      "seek": 54826,
      "start": 549.7,
      "end": 552.18,
      "text": " and you want to quickly open it up",
      "tokens": [
        50435,
        290,
        345,
        765,
        284,
        2952,
        1280,
        340,
        510,
        50559
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06705775468245796,
      "compression_ratio": 1.7932330827067668,
      "no_speech_prob": 0.0012851693900302052
    },
    {
      "id": 169,
      "seek": 54826,
      "start": 552.18,
      "end": 553.86,
      "text": " and play around with it and close it again, right?",
      "tokens": [
        50559,
        290,
        711,
        1088,
        351,
        340,
        290,
        1969,
        340,
        757,
        11,
        826,
        30,
        50643
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06705775468245796,
      "compression_ratio": 1.7932330827067668,
      "no_speech_prob": 0.0012851693900302052
    },
    {
      "id": 170,
      "seek": 54826,
      "start": 554.8199999999999,
      "end": 556.26,
      "text": " That seems like a reasonable thing.",
      "tokens": [
        50691,
        1320,
        2331,
        588,
        257,
        6397,
        1517,
        13,
        50763
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06705775468245796,
      "compression_ratio": 1.7932330827067668,
      "no_speech_prob": 0.0012851693900302052
    },
    {
      "id": 171,
      "seek": 54826,
      "start": 557.14,
      "end": 559.3,
      "text": " Okay, so I've got data that is like",
      "tokens": [
        50807,
        16805,
        11,
        523,
        314,
        1053,
        1392,
        1366,
        326,
        318,
        588,
        50915
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06705775468245796,
      "compression_ratio": 1.7932330827067668,
      "no_speech_prob": 0.0012851693900302052
    },
    {
      "id": 172,
      "seek": 54826,
      "start": 560.26,
      "end": 562.9,
      "text": " a thing that's a million lines long",
      "tokens": [
        50963,
        257,
        1517,
        326,
        338,
        257,
        1510,
        3951,
        890,
        51095
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06705775468245796,
      "compression_ratio": 1.7932330827067668,
      "no_speech_prob": 0.0012851693900302052
    },
    {
      "id": 173,
      "seek": 54826,
      "start": 562.9,
      "end": 563.9399999999999,
      "text": " or something ridiculous.",
      "tokens": [
        51095,
        393,
        1223,
        11441,
        13,
        51147
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06705775468245796,
      "compression_ratio": 1.7932330827067668,
      "no_speech_prob": 0.0012851693900302052
    },
    {
      "id": 174,
      "seek": 54826,
      "start": 563.9399999999999,
      "end": 565.62,
      "text": " And I'll probably set something up like this",
      "tokens": [
        51147,
        843,
        314,
        1183,
        2192,
        900,
        1223,
        510,
        588,
        428,
        51231
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06705775468245796,
      "compression_ratio": 1.7932330827067668,
      "no_speech_prob": 0.0012851693900302052
    },
    {
      "id": 175,
      "seek": 54826,
      "start": 565.62,
      "end": 567.3,
      "text": " to say, okay, here's some data",
      "tokens": [
        51231,
        284,
        910,
        11,
        8788,
        11,
        994,
        338,
        617,
        1366,
        51315
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06705775468245796,
      "compression_ratio": 1.7932330827067668,
      "no_speech_prob": 0.0012851693900302052
    },
    {
      "id": 176,
      "seek": 54826,
      "start": 567.3,
      "end": 568.98,
      "text": " that's really, really long",
      "tokens": [
        51315,
        326,
        338,
        1107,
        11,
        1107,
        890,
        51399
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06705775468245796,
      "compression_ratio": 1.7932330827067668,
      "no_speech_prob": 0.0012851693900302052
    },
    {
      "id": 177,
      "seek": 54826,
      "start": 568.98,
      "end": 572.18,
      "text": " and on each thing I need to do something",
      "tokens": [
        51399,
        290,
        319,
        1123,
        1517,
        314,
        761,
        284,
        466,
        1223,
        51559
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06705775468245796,
      "compression_ratio": 1.7932330827067668,
      "no_speech_prob": 0.0012851693900302052
    },
    {
      "id": 178,
      "seek": 54826,
      "start": 572.18,
      "end": 574.9,
      "text": " and then save that in another data file, right?",
      "tokens": [
        51559,
        290,
        788,
        3613,
        326,
        287,
        1194,
        1366,
        2393,
        11,
        826,
        30,
        51695
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06705775468245796,
      "compression_ratio": 1.7932330827067668,
      "no_speech_prob": 0.0012851693900302052
    },
    {
      "id": 179,
      "seek": 54826,
      "start": 575.54,
      "end": 577.54,
      "text": " Great, okay, so what we want to do",
      "tokens": [
        51727,
        3878,
        11,
        8788,
        11,
        523,
        644,
        356,
        765,
        284,
        466,
        51827
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06705775468245796,
      "compression_ratio": 1.7932330827067668,
      "no_speech_prob": 0.0012851693900302052
    },
    {
      "id": 180,
      "seek": 57826,
      "start": 578.8199999999999,
      "end": 582.02,
      "text": " is say like for each line in the thing,",
      "tokens": [
        50391,
        318,
        910,
        588,
        329,
        1123,
        1627,
        287,
        262,
        1517,
        11,
        50551
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09405010322044635,
      "compression_ratio": 1.6460176991150441,
      "no_speech_prob": 0.00039871412445791066
    },
    {
      "id": 181,
      "seek": 57826,
      "start": 583.06,
      "end": 584.9,
      "text": " do this thing and then stop.",
      "tokens": [
        50603,
        466,
        428,
        1517,
        290,
        788,
        2245,
        13,
        50695
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09405010322044635,
      "compression_ratio": 1.6460176991150441,
      "no_speech_prob": 0.00039871412445791066
    },
    {
      "id": 182,
      "seek": 57826,
      "start": 585.62,
      "end": 587.3,
      "text": " Cool, very happy with that.",
      "tokens": [
        50731,
        15226,
        11,
        845,
        3772,
        351,
        326,
        13,
        50815
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09405010322044635,
      "compression_ratio": 1.6460176991150441,
      "no_speech_prob": 0.00039871412445791066
    },
    {
      "id": 183,
      "seek": 57826,
      "start": 587.9399999999999,
      "end": 592.1,
      "text": " Okay, so how would you do that in Python?",
      "tokens": [
        50847,
        16805,
        11,
        523,
        703,
        561,
        345,
        466,
        326,
        287,
        11361,
        30,
        51055
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09405010322044635,
      "compression_ratio": 1.6460176991150441,
      "no_speech_prob": 0.00039871412445791066
    },
    {
      "id": 184,
      "seek": 57826,
      "start": 592.98,
      "end": 594.1,
      "text": " Here's the setup.",
      "tokens": [
        51099,
        3423,
        338,
        262,
        9058,
        13,
        51155
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09405010322044635,
      "compression_ratio": 1.6460176991150441,
      "no_speech_prob": 0.00039871412445791066
    },
    {
      "id": 185,
      "seek": 57826,
      "start": 594.1,
      "end": 596.5,
      "text": " How to do that in Julia is the setup.",
      "tokens": [
        51155,
        1374,
        284,
        466,
        326,
        287,
        22300,
        318,
        262,
        9058,
        13,
        51275
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09405010322044635,
      "compression_ratio": 1.6460176991150441,
      "no_speech_prob": 0.00039871412445791066
    },
    {
      "id": 186,
      "seek": 57826,
      "start": 596.5,
      "end": 599.14,
      "text": " Now, obviously, I'll then show and say,",
      "tokens": [
        51275,
        2735,
        11,
        6189,
        11,
        314,
        1183,
        788,
        905,
        290,
        910,
        11,
        51407
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09405010322044635,
      "compression_ratio": 1.6460176991150441,
      "no_speech_prob": 0.00039871412445791066
    },
    {
      "id": 187,
      "seek": 57826,
      "start": 599.14,
      "end": 601.38,
      "text": " okay, and here's kind of the difference",
      "tokens": [
        51407,
        8788,
        11,
        290,
        994,
        338,
        1611,
        286,
        262,
        3580,
        51519
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09405010322044635,
      "compression_ratio": 1.6460176991150441,
      "no_speech_prob": 0.00039871412445791066
    },
    {
      "id": 188,
      "seek": 57826,
      "start": 601.38,
      "end": 602.98,
      "text": " in speed between the two, right?",
      "tokens": [
        51519,
        287,
        2866,
        1022,
        262,
        734,
        11,
        826,
        30,
        51599
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09405010322044635,
      "compression_ratio": 1.6460176991150441,
      "no_speech_prob": 0.00039871412445791066
    },
    {
      "id": 189,
      "seek": 57826,
      "start": 603.7,
      "end": 605.78,
      "text": " And the difference in complexity.",
      "tokens": [
        51635,
        843,
        262,
        3580,
        287,
        13357,
        13,
        51739
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09405010322044635,
      "compression_ratio": 1.6460176991150441,
      "no_speech_prob": 0.00039871412445791066
    },
    {
      "id": 190,
      "seek": 57826,
      "start": 605.78,
      "end": 607.54,
      "text": " And I'll try to make the Julia",
      "tokens": [
        51739,
        843,
        314,
        1183,
        1949,
        284,
        787,
        262,
        22300,
        51827
      ],
      "temperature": 0.0,
      "avg_logprob": -0.09405010322044635,
      "compression_ratio": 1.6460176991150441,
      "no_speech_prob": 0.00039871412445791066
    },
    {
      "id": 191,
      "seek": 60754,
      "start": 607.54,
      "end": 610.0999999999999,
      "text": " look as close to the Python as I can.",
      "tokens": [
        50363,
        804,
        355,
        1969,
        284,
        262,
        11361,
        355,
        314,
        460,
        13,
        50491
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08448588542449169,
      "compression_ratio": 1.7338709677419355,
      "no_speech_prob": 0.00034783006412908435
    },
    {
      "id": 192,
      "seek": 60754,
      "start": 610.66,
      "end": 612.66,
      "text": " And I think that's going to be really important",
      "tokens": [
        50519,
        843,
        314,
        892,
        326,
        338,
        1016,
        284,
        307,
        1107,
        1593,
        50619
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08448588542449169,
      "compression_ratio": 1.7338709677419355,
      "no_speech_prob": 0.00034783006412908435
    },
    {
      "id": 193,
      "seek": 60754,
      "start": 613.2199999999999,
      "end": 614.66,
      "text": " because what I then want to do is say,",
      "tokens": [
        50647,
        780,
        644,
        314,
        788,
        765,
        284,
        466,
        318,
        910,
        11,
        50719
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08448588542449169,
      "compression_ratio": 1.7338709677419355,
      "no_speech_prob": 0.00034783006412908435
    },
    {
      "id": 194,
      "seek": 60754,
      "start": 614.66,
      "end": 618.0999999999999,
      "text": " okay, let's look at how we would speed this up",
      "tokens": [
        50719,
        8788,
        11,
        1309,
        338,
        804,
        379,
        703,
        356,
        561,
        2866,
        428,
        510,
        50891
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08448588542449169,
      "compression_ratio": 1.7338709677419355,
      "no_speech_prob": 0.00034783006412908435
    },
    {
      "id": 195,
      "seek": 60754,
      "start": 618.0999999999999,
      "end": 618.9,
      "text": " in the two languages,",
      "tokens": [
        50891,
        287,
        262,
        734,
        8950,
        11,
        50931
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08448588542449169,
      "compression_ratio": 1.7338709677419355,
      "no_speech_prob": 0.00034783006412908435
    },
    {
      "id": 196,
      "seek": 60754,
      "start": 618.9,
      "end": 620.74,
      "text": " because I think this is the really important thing.",
      "tokens": [
        50931,
        780,
        314,
        892,
        428,
        318,
        262,
        1107,
        1593,
        1517,
        13,
        51023
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08448588542449169,
      "compression_ratio": 1.7338709677419355,
      "no_speech_prob": 0.00034783006412908435
    },
    {
      "id": 197,
      "seek": 60754,
      "start": 621.4599999999999,
      "end": 624.26,
      "text": " Python is very good at quick and dirty,",
      "tokens": [
        51059,
        11361,
        318,
        845,
        922,
        379,
        2068,
        290,
        11841,
        11,
        51199
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08448588542449169,
      "compression_ratio": 1.7338709677419355,
      "no_speech_prob": 0.00034783006412908435
    },
    {
      "id": 198,
      "seek": 60754,
      "start": 624.8199999999999,
      "end": 626.42,
      "text": " but taking quick and dirty",
      "tokens": [
        51227,
        475,
        2263,
        2068,
        290,
        11841,
        51307
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08448588542449169,
      "compression_ratio": 1.7338709677419355,
      "no_speech_prob": 0.00034783006412908435
    },
    {
      "id": 199,
      "seek": 60754,
      "start": 626.42,
      "end": 629.54,
      "text": " and turning it into better and faster",
      "tokens": [
        51307,
        290,
        6225,
        340,
        656,
        1365,
        290,
        5443,
        51463
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08448588542449169,
      "compression_ratio": 1.7338709677419355,
      "no_speech_prob": 0.00034783006412908435
    },
    {
      "id": 200,
      "seek": 60754,
      "start": 629.54,
      "end": 632.0999999999999,
      "text": " and more performant and optimized is hard.",
      "tokens": [
        51463,
        290,
        517,
        1620,
        415,
        290,
        23392,
        318,
        1327,
        13,
        51591
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08448588542449169,
      "compression_ratio": 1.7338709677419355,
      "no_speech_prob": 0.00034783006412908435
    },
    {
      "id": 201,
      "seek": 60754,
      "start": 632.9,
      "end": 636.5799999999999,
      "text": " Julia is fairly equivalent to Python",
      "tokens": [
        51631,
        22300,
        318,
        6547,
        7548,
        284,
        11361,
        51815
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08448588542449169,
      "compression_ratio": 1.7338709677419355,
      "no_speech_prob": 0.00034783006412908435
    },
    {
      "id": 202,
      "seek": 63658,
      "start": 636.58,
      "end": 638.9000000000001,
      "text": " for quick and dirty, right?",
      "tokens": [
        50363,
        329,
        2068,
        290,
        11841,
        11,
        826,
        30,
        50479
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10544171494044614,
      "compression_ratio": 1.561904761904762,
      "no_speech_prob": 0.005094483960419893
    },
    {
      "id": 203,
      "seek": 63658,
      "start": 639.62,
      "end": 640.6600000000001,
      "text": " Slightly different syntax,",
      "tokens": [
        50515,
        49365,
        1180,
        15582,
        11,
        50567
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10544171494044614,
      "compression_ratio": 1.561904761904762,
      "no_speech_prob": 0.005094483960419893
    },
    {
      "id": 204,
      "seek": 63658,
      "start": 640.6600000000001,
      "end": 642.9000000000001,
      "text": " but fundamentally you're doing roughly the same thing,",
      "tokens": [
        50567,
        475,
        17640,
        345,
        821,
        1804,
        7323,
        262,
        976,
        1517,
        11,
        50679
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10544171494044614,
      "compression_ratio": 1.561904761904762,
      "no_speech_prob": 0.005094483960419893
    },
    {
      "id": 205,
      "seek": 63658,
      "start": 643.86,
      "end": 647.3000000000001,
      "text": " but turning it into something that is",
      "tokens": [
        50727,
        475,
        6225,
        340,
        656,
        1223,
        326,
        318,
        50899
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10544171494044614,
      "compression_ratio": 1.561904761904762,
      "no_speech_prob": 0.005094483960419893
    },
    {
      "id": 206,
      "seek": 63658,
      "start": 650.0200000000001,
      "end": 652.74,
      "text": " performant and optimized is much easier.",
      "tokens": [
        51035,
        1620,
        415,
        290,
        23392,
        318,
        881,
        4577,
        13,
        51171
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10544171494044614,
      "compression_ratio": 1.561904761904762,
      "no_speech_prob": 0.005094483960419893
    },
    {
      "id": 207,
      "seek": 63658,
      "start": 654.0200000000001,
      "end": 657.22,
      "text": " Yeah, I really like that framing of the thing.",
      "tokens": [
        51235,
        9425,
        11,
        314,
        1107,
        588,
        326,
        30811,
        286,
        262,
        1517,
        13,
        51395
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10544171494044614,
      "compression_ratio": 1.561904761904762,
      "no_speech_prob": 0.005094483960419893
    },
    {
      "id": 208,
      "seek": 63658,
      "start": 657.86,
      "end": 661.3000000000001,
      "text": " So what I'll do is I'll say something along the lines of,",
      "tokens": [
        51427,
        1406,
        644,
        314,
        1183,
        466,
        318,
        314,
        1183,
        910,
        1223,
        1863,
        262,
        3951,
        286,
        11,
        51599
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10544171494044614,
      "compression_ratio": 1.561904761904762,
      "no_speech_prob": 0.005094483960419893
    },
    {
      "id": 209,
      "seek": 63658,
      "start": 662.34,
      "end": 663.86,
      "text": " okay, so we're going to go through",
      "tokens": [
        51651,
        8788,
        11,
        523,
        356,
        821,
        1016,
        284,
        467,
        832,
        51727
      ],
      "temperature": 0.0,
      "avg_logprob": -0.10544171494044614,
      "compression_ratio": 1.561904761904762,
      "no_speech_prob": 0.005094483960419893
    },
    {
      "id": 210,
      "seek": 66386,
      "start": 664.82,
      "end": 667.38,
      "text": " the manner in which someone would",
      "tokens": [
        50411,
        262,
        5642,
        287,
        543,
        2130,
        561,
        50539
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13108573839502427,
      "compression_ratio": 1.6452991452991452,
      "no_speech_prob": 0.002770110033452511
    },
    {
      "id": 211,
      "seek": 66386,
      "start": 668.74,
      "end": 669.62,
      "text": " create a...",
      "tokens": [
        50607,
        2251,
        257,
        986,
        50651
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13108573839502427,
      "compression_ratio": 1.6452991452991452,
      "no_speech_prob": 0.002770110033452511
    },
    {
      "id": 212,
      "seek": 66386,
      "start": 673.3000000000001,
      "end": 675.78,
      "text": " end up with a useful tool in astronomy.",
      "tokens": [
        50835,
        886,
        510,
        351,
        257,
        4465,
        2891,
        287,
        37145,
        13,
        50959
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13108573839502427,
      "compression_ratio": 1.6452991452991452,
      "no_speech_prob": 0.002770110033452511
    },
    {
      "id": 213,
      "seek": 66386,
      "start": 675.78,
      "end": 678.02,
      "text": " Because I think I want to phrase Julia as",
      "tokens": [
        50959,
        4362,
        314,
        892,
        314,
        765,
        284,
        9546,
        22300,
        355,
        51071
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13108573839502427,
      "compression_ratio": 1.6452991452991452,
      "no_speech_prob": 0.002770110033452511
    },
    {
      "id": 214,
      "seek": 66386,
      "start": 678.82,
      "end": 680.9,
      "text": " the reason, the thing you should use this for",
      "tokens": [
        51111,
        262,
        1738,
        11,
        262,
        1517,
        345,
        815,
        779,
        428,
        329,
        51215
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13108573839502427,
      "compression_ratio": 1.6452991452991452,
      "no_speech_prob": 0.002770110033452511
    },
    {
      "id": 215,
      "seek": 66386,
      "start": 680.9,
      "end": 683.54,
      "text": " is building tools in astronomy, right?",
      "tokens": [
        51215,
        318,
        2615,
        4899,
        287,
        37145,
        11,
        826,
        30,
        51347
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13108573839502427,
      "compression_ratio": 1.6452991452991452,
      "no_speech_prob": 0.002770110033452511
    },
    {
      "id": 216,
      "seek": 66386,
      "start": 683.54,
      "end": 687.14,
      "text": " When it comes to here's some data plotted for a paper,",
      "tokens": [
        51347,
        1649,
        340,
        2058,
        284,
        994,
        338,
        617,
        1366,
        37515,
        329,
        257,
        3348,
        11,
        51527
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13108573839502427,
      "compression_ratio": 1.6452991452991452,
      "no_speech_prob": 0.002770110033452511
    },
    {
      "id": 217,
      "seek": 66386,
      "start": 687.14,
      "end": 689.86,
      "text": " Python's fine for that. Julia can do that, absolutely.",
      "tokens": [
        51527,
        11361,
        338,
        3734,
        329,
        326,
        13,
        22300,
        460,
        466,
        326,
        11,
        5543,
        13,
        51663
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13108573839502427,
      "compression_ratio": 1.6452991452991452,
      "no_speech_prob": 0.002770110033452511
    },
    {
      "id": 218,
      "seek": 66386,
      "start": 689.86,
      "end": 693.22,
      "text": " But Julia can't necessarily do that better than Python, right?",
      "tokens": [
        51663,
        887,
        22300,
        460,
        470,
        6646,
        466,
        326,
        1365,
        621,
        11361,
        11,
        826,
        30,
        51831
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13108573839502427,
      "compression_ratio": 1.6452991452991452,
      "no_speech_prob": 0.002770110033452511
    },
    {
      "id": 219,
      "seek": 69386,
      "start": 694.82,
      "end": 695.94,
      "text": " And it comes to...",
      "tokens": [
        50411,
        843,
        340,
        2058,
        284,
        986,
        50467
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18494985753839666,
      "compression_ratio": 1.7737556561085972,
      "no_speech_prob": 0.00456621777266264
    },
    {
      "id": 220,
      "seek": 69386,
      "start": 700.34,
      "end": 703.54,
      "text": " like if you're doing more advanced computing stuff.",
      "tokens": [
        50687,
        588,
        611,
        345,
        821,
        1804,
        517,
        6190,
        14492,
        3404,
        13,
        50847
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18494985753839666,
      "compression_ratio": 1.7737556561085972,
      "no_speech_prob": 0.00456621777266264
    },
    {
      "id": 221,
      "seek": 69386,
      "start": 703.54,
      "end": 706.02,
      "text": " So yeah, I mean it's worth mentioning,",
      "tokens": [
        50847,
        1406,
        10194,
        11,
        314,
        1612,
        340,
        338,
        2861,
        20862,
        11,
        50971
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18494985753839666,
      "compression_ratio": 1.7737556561085972,
      "no_speech_prob": 0.00456621777266264
    },
    {
      "id": 222,
      "seek": 69386,
      "start": 706.02,
      "end": 708.02,
      "text": " like if you're doing more advanced computing stuff,",
      "tokens": [
        50971,
        588,
        611,
        345,
        821,
        1804,
        517,
        6190,
        14492,
        3404,
        11,
        51071
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18494985753839666,
      "compression_ratio": 1.7737556561085972,
      "no_speech_prob": 0.00456621777266264
    },
    {
      "id": 223,
      "seek": 69386,
      "start": 708.82,
      "end": 710.58,
      "text": " like doing machine learning,",
      "tokens": [
        51111,
        588,
        1804,
        4572,
        4673,
        11,
        51199
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18494985753839666,
      "compression_ratio": 1.7737556561085972,
      "no_speech_prob": 0.00456621777266264
    },
    {
      "id": 224,
      "seek": 69386,
      "start": 711.54,
      "end": 713.14,
      "text": " doing high performance computing,",
      "tokens": [
        51247,
        1804,
        1029,
        2854,
        14492,
        11,
        51327
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18494985753839666,
      "compression_ratio": 1.7737556561085972,
      "no_speech_prob": 0.00456621777266264
    },
    {
      "id": 225,
      "seek": 69386,
      "start": 713.14,
      "end": 714.82,
      "text": " doing GPU computing,",
      "tokens": [
        51327,
        1804,
        11362,
        14492,
        11,
        51411
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18494985753839666,
      "compression_ratio": 1.7737556561085972,
      "no_speech_prob": 0.00456621777266264
    },
    {
      "id": 226,
      "seek": 69386,
      "start": 714.82,
      "end": 717.46,
      "text": " all of these things are absolutely doable in Julia",
      "tokens": [
        51411,
        477,
        286,
        777,
        1243,
        389,
        5543,
        466,
        540,
        287,
        22300,
        51543
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18494985753839666,
      "compression_ratio": 1.7737556561085972,
      "no_speech_prob": 0.00456621777266264
    },
    {
      "id": 227,
      "seek": 69386,
      "start": 717.46,
      "end": 719.78,
      "text": " and have strong things.",
      "tokens": [
        51543,
        290,
        423,
        1913,
        1243,
        13,
        51659
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18494985753839666,
      "compression_ratio": 1.7737556561085972,
      "no_speech_prob": 0.00456621777266264
    },
    {
      "id": 228,
      "seek": 69386,
      "start": 719.78,
      "end": 721.0600000000001,
      "text": " And I'll say it, yeah.",
      "tokens": [
        51659,
        843,
        314,
        1183,
        910,
        340,
        11,
        10194,
        13,
        51723
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18494985753839666,
      "compression_ratio": 1.7737556561085972,
      "no_speech_prob": 0.00456621777266264
    },
    {
      "id": 229,
      "seek": 69386,
      "start": 721.0600000000001,
      "end": 721.94,
      "text": " Yeah, okay.",
      "tokens": [
        51723,
        9425,
        11,
        8788,
        13,
        51767
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18494985753839666,
      "compression_ratio": 1.7737556561085972,
      "no_speech_prob": 0.00456621777266264
    },
    {
      "id": 230,
      "seek": 69386,
      "start": 721.94,
      "end": 723.0600000000001,
      "text": " So the introduction I'll go through,",
      "tokens": [
        51767,
        1406,
        262,
        9793,
        314,
        1183,
        467,
        832,
        11,
        51823
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18494985753839666,
      "compression_ratio": 1.7737556561085972,
      "no_speech_prob": 0.00456621777266264
    },
    {
      "id": 231,
      "seek": 72306,
      "start": 723.06,
      "end": 724.5,
      "text": " these are like the highlights of Julia.",
      "tokens": [
        50363,
        777,
        389,
        588,
        262,
        11330,
        286,
        22300,
        13,
        50435
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08064299114679886,
      "compression_ratio": 1.639676113360324,
      "no_speech_prob": 0.0016841274918988347
    },
    {
      "id": 232,
      "seek": 72306,
      "start": 725.6999999999999,
      "end": 729.6199999999999,
      "text": " But when it comes to how you guys and me and I",
      "tokens": [
        50495,
        887,
        618,
        340,
        2058,
        284,
        703,
        345,
        3730,
        290,
        502,
        290,
        314,
        50691
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08064299114679886,
      "compression_ratio": 1.639676113360324,
      "no_speech_prob": 0.0016841274918988347
    },
    {
      "id": 233,
      "seek": 72306,
      "start": 729.6199999999999,
      "end": 731.38,
      "text": " are most likely going to use it,",
      "tokens": [
        50691,
        389,
        749,
        1884,
        1016,
        284,
        779,
        340,
        11,
        50779
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08064299114679886,
      "compression_ratio": 1.639676113360324,
      "no_speech_prob": 0.0016841274918988347
    },
    {
      "id": 234,
      "seek": 72306,
      "start": 733.3,
      "end": 737.6999999999999,
      "text": " you need to look at how we use code in general, right?",
      "tokens": [
        50875,
        345,
        761,
        284,
        804,
        379,
        703,
        356,
        779,
        2438,
        287,
        2276,
        11,
        826,
        30,
        51095
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08064299114679886,
      "compression_ratio": 1.639676113360324,
      "no_speech_prob": 0.0016841274918988347
    },
    {
      "id": 235,
      "seek": 72306,
      "start": 738.5799999999999,
      "end": 741.3,
      "text": " Most of us are not computer scientists,",
      "tokens": [
        51139,
        4042,
        286,
        514,
        389,
        407,
        3644,
        5519,
        11,
        51275
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08064299114679886,
      "compression_ratio": 1.639676113360324,
      "no_speech_prob": 0.0016841274918988347
    },
    {
      "id": 236,
      "seek": 72306,
      "start": 741.3,
      "end": 742.5,
      "text": " we're astronomers.",
      "tokens": [
        51275,
        356,
        821,
        33162,
        13,
        51335
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08064299114679886,
      "compression_ratio": 1.639676113360324,
      "no_speech_prob": 0.0016841274918988347
    },
    {
      "id": 237,
      "seek": 72306,
      "start": 742.5,
      "end": 744.18,
      "text": " Which means most of the time,",
      "tokens": [
        51335,
        9022,
        1724,
        749,
        286,
        262,
        640,
        11,
        51419
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08064299114679886,
      "compression_ratio": 1.639676113360324,
      "no_speech_prob": 0.0016841274918988347
    },
    {
      "id": 238,
      "seek": 72306,
      "start": 744.18,
      "end": 747.9399999999999,
      "text": " the code we write is in the service of doing astronomy.",
      "tokens": [
        51419,
        262,
        2438,
        356,
        3551,
        318,
        287,
        262,
        2139,
        286,
        1804,
        37145,
        13,
        51607
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08064299114679886,
      "compression_ratio": 1.639676113360324,
      "no_speech_prob": 0.0016841274918988347
    },
    {
      "id": 239,
      "seek": 72306,
      "start": 747.9399999999999,
      "end": 750.18,
      "text": " We're not writing code for the sake of code.",
      "tokens": [
        51607,
        775,
        821,
        407,
        3597,
        2438,
        329,
        262,
        11060,
        286,
        2438,
        13,
        51719
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08064299114679886,
      "compression_ratio": 1.639676113360324,
      "no_speech_prob": 0.0016841274918988347
    },
    {
      "id": 240,
      "seek": 72306,
      "start": 750.18,
      "end": 752.18,
      "text": " And I say we, obviously I do that a lot.",
      "tokens": [
        51719,
        843,
        314,
        910,
        356,
        11,
        6189,
        314,
        466,
        326,
        257,
        1256,
        13,
        51819
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08064299114679886,
      "compression_ratio": 1.639676113360324,
      "no_speech_prob": 0.0016841274918988347
    },
    {
      "id": 241,
      "seek": 75218,
      "start": 752.18,
      "end": 759.38,
      "text": " But what I mean is that the function of code within astronomy",
      "tokens": [
        50363,
        887,
        644,
        314,
        1612,
        318,
        326,
        262,
        2163,
        286,
        2438,
        1626,
        37145,
        50723
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08982029925571398,
      "compression_ratio": 1.6009389671361502,
      "no_speech_prob": 0.0008897878578864038
    },
    {
      "id": 242,
      "seek": 75218,
      "start": 759.38,
      "end": 761.54,
      "text": " is to produce something that can be used.",
      "tokens": [
        50723,
        318,
        284,
        4439,
        1223,
        326,
        460,
        307,
        973,
        13,
        50831
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08982029925571398,
      "compression_ratio": 1.6009389671361502,
      "no_speech_prob": 0.0008897878578864038
    },
    {
      "id": 243,
      "seek": 75218,
      "start": 762.42,
      "end": 763.54,
      "text": " It doesn't need to be...",
      "tokens": [
        50875,
        632,
        1595,
        470,
        761,
        284,
        307,
        986,
        50931
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08982029925571398,
      "compression_ratio": 1.6009389671361502,
      "no_speech_prob": 0.0008897878578864038
    },
    {
      "id": 244,
      "seek": 75218,
      "start": 764.42,
      "end": 769.14,
      "text": " But yeah, produce a very specialized tool that can be used, right?",
      "tokens": [
        50975,
        887,
        10194,
        11,
        4439,
        257,
        845,
        16976,
        2891,
        326,
        460,
        307,
        973,
        11,
        826,
        30,
        51211
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08982029925571398,
      "compression_ratio": 1.6009389671361502,
      "no_speech_prob": 0.0008897878578864038
    },
    {
      "id": 245,
      "seek": 75218,
      "start": 769.14,
      "end": 774.18,
      "text": " If you're looking at languages like Rust and C++",
      "tokens": [
        51211,
        1002,
        345,
        821,
        2045,
        379,
        8950,
        588,
        17103,
        290,
        327,
        4880,
        51463
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08982029925571398,
      "compression_ratio": 1.6009389671361502,
      "no_speech_prob": 0.0008897878578864038
    },
    {
      "id": 246,
      "seek": 75218,
      "start": 774.18,
      "end": 775.78,
      "text": " and all these other languages,",
      "tokens": [
        51463,
        290,
        477,
        777,
        584,
        8950,
        11,
        51543
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08982029925571398,
      "compression_ratio": 1.6009389671361502,
      "no_speech_prob": 0.0008897878578864038
    },
    {
      "id": 247,
      "seek": 75218,
      "start": 775.78,
      "end": 779.9399999999999,
      "text": " they're very good at building very powerful general tools, right?",
      "tokens": [
        51543,
        484,
        821,
        845,
        922,
        379,
        2615,
        845,
        3665,
        2276,
        4899,
        11,
        826,
        30,
        51751
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08982029925571398,
      "compression_ratio": 1.6009389671361502,
      "no_speech_prob": 0.0008897878578864038
    },
    {
      "id": 248,
      "seek": 77994,
      "start": 779.94,
      "end": 784.6600000000001,
      "text": " So this is a tool that can be used by anyone for something big, right?",
      "tokens": [
        50363,
        1406,
        428,
        318,
        257,
        2891,
        326,
        460,
        307,
        973,
        416,
        2687,
        329,
        1223,
        1263,
        11,
        826,
        30,
        50599
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08424293872007389,
      "compression_ratio": 1.5732758620689655,
      "no_speech_prob": 0.000651563866995275
    },
    {
      "id": 249,
      "seek": 77994,
      "start": 784.6600000000001,
      "end": 789.3000000000001,
      "text": " You're looking at like Linux or a web browser or something like that.",
      "tokens": [
        50599,
        921,
        821,
        2045,
        379,
        588,
        7020,
        393,
        257,
        3992,
        6444,
        393,
        1223,
        588,
        326,
        13,
        50831
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08424293872007389,
      "compression_ratio": 1.5732758620689655,
      "no_speech_prob": 0.000651563866995275
    },
    {
      "id": 250,
      "seek": 77994,
      "start": 789.3000000000001,
      "end": 791.3000000000001,
      "text": " That's what those tools are used for.",
      "tokens": [
        50831,
        1320,
        338,
        644,
        883,
        4899,
        389,
        973,
        329,
        13,
        50931
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08424293872007389,
      "compression_ratio": 1.5732758620689655,
      "no_speech_prob": 0.000651563866995275
    },
    {
      "id": 251,
      "seek": 77994,
      "start": 791.3000000000001,
      "end": 794.4200000000001,
      "text": " If you look at Python, there's kind of two branches.",
      "tokens": [
        50931,
        1002,
        345,
        804,
        379,
        11361,
        11,
        612,
        338,
        1611,
        286,
        734,
        13737,
        13,
        51087
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08424293872007389,
      "compression_ratio": 1.5732758620689655,
      "no_speech_prob": 0.000651563866995275
    },
    {
      "id": 252,
      "seek": 77994,
      "start": 794.4200000000001,
      "end": 798.9000000000001,
      "text": " Pure Python, quick and dirty script that you run a few times and then never again.",
      "tokens": [
        51087,
        17129,
        11361,
        11,
        2068,
        290,
        11841,
        4226,
        326,
        345,
        1057,
        257,
        1178,
        1661,
        290,
        788,
        1239,
        757,
        13,
        51311
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08424293872007389,
      "compression_ratio": 1.5732758620689655,
      "no_speech_prob": 0.000651563866995275
    },
    {
      "id": 253,
      "seek": 77994,
      "start": 799.7,
      "end": 805.1400000000001,
      "text": " Or a wrapper around a general purpose tool, right?",
      "tokens": [
        51351,
        1471,
        257,
        29908,
        1088,
        257,
        2276,
        4007,
        2891,
        11,
        826,
        30,
        51623
      ],
      "temperature": 0.0,
      "avg_logprob": -0.08424293872007389,
      "compression_ratio": 1.5732758620689655,
      "no_speech_prob": 0.000651563866995275
    },
    {
      "id": 254,
      "seek": 80514,
      "start": 805.14,
      "end": 811.38,
      "text": " So this creates a general purpose tool in C or C++ or Rust.",
      "tokens": [
        50363,
        1406,
        428,
        8075,
        257,
        2276,
        4007,
        2891,
        287,
        327,
        393,
        327,
        4880,
        393,
        17103,
        13,
        50675
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0799918486693195,
      "compression_ratio": 1.6680497925311204,
      "no_speech_prob": 0.001703384448774159
    },
    {
      "id": 255,
      "seek": 80514,
      "start": 811.38,
      "end": 814.18,
      "text": " And then using that tool is really obnoxious.",
      "tokens": [
        50675,
        843,
        788,
        1262,
        326,
        2891,
        318,
        1107,
        43283,
        13,
        50815
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0799918486693195,
      "compression_ratio": 1.6680497925311204,
      "no_speech_prob": 0.001703384448774159
    },
    {
      "id": 256,
      "seek": 80514,
      "start": 814.18,
      "end": 819.3,
      "text": " And, you know, making that tool play nicely with file writing and with plotting",
      "tokens": [
        50815,
        843,
        11,
        345,
        760,
        11,
        1642,
        326,
        2891,
        711,
        16576,
        351,
        2393,
        3597,
        290,
        351,
        29353,
        51071
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0799918486693195,
      "compression_ratio": 1.6680497925311204,
      "no_speech_prob": 0.001703384448774159
    },
    {
      "id": 257,
      "seek": 80514,
      "start": 819.3,
      "end": 821.62,
      "text": " and with all of the other things that we like to do.",
      "tokens": [
        51071,
        290,
        351,
        477,
        286,
        262,
        584,
        1243,
        326,
        356,
        588,
        284,
        466,
        13,
        51187
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0799918486693195,
      "compression_ratio": 1.6680497925311204,
      "no_speech_prob": 0.001703384448774159
    },
    {
      "id": 258,
      "seek": 80514,
      "start": 821.62,
      "end": 822.74,
      "text": " That's all annoying.",
      "tokens": [
        51187,
        1320,
        338,
        477,
        15774,
        13,
        51243
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0799918486693195,
      "compression_ratio": 1.6680497925311204,
      "no_speech_prob": 0.001703384448774159
    },
    {
      "id": 259,
      "seek": 80514,
      "start": 822.74,
      "end": 827.14,
      "text": " And so we do a Python wrapper to make it easier to use the tool, right?",
      "tokens": [
        51243,
        843,
        523,
        356,
        466,
        257,
        11361,
        29908,
        284,
        787,
        340,
        4577,
        284,
        779,
        262,
        2891,
        11,
        826,
        30,
        51463
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0799918486693195,
      "compression_ratio": 1.6680497925311204,
      "no_speech_prob": 0.001703384448774159
    },
    {
      "id": 260,
      "seek": 80514,
      "start": 827.78,
      "end": 834.9,
      "text": " Oftentimes Python is a way of using tools that other people have made.",
      "tokens": [
        51495,
        440,
        701,
        43598,
        11361,
        318,
        257,
        835,
        286,
        1262,
        4899,
        326,
        584,
        661,
        423,
        925,
        13,
        51851
      ],
      "temperature": 0.0,
      "avg_logprob": -0.0799918486693195,
      "compression_ratio": 1.6680497925311204,
      "no_speech_prob": 0.001703384448774159
    },
    {
      "id": 261,
      "seek": 83514,
      "start": 835.6999999999999,
      "end": 836.18,
      "text": " Right?",
      "tokens": [
        50391,
        6498,
        30,
        50415
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06759433918171101,
      "compression_ratio": 1.815450643776824,
      "no_speech_prob": 0.0012195892632007599
    },
    {
      "id": 262,
      "seek": 83514,
      "start": 836.18,
      "end": 837.9399999999999,
      "text": " But what that means is you kind of need...",
      "tokens": [
        50415,
        887,
        644,
        326,
        1724,
        318,
        345,
        1611,
        286,
        761,
        986,
        50503
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06759433918171101,
      "compression_ratio": 1.815450643776824,
      "no_speech_prob": 0.0012195892632007599
    },
    {
      "id": 263,
      "seek": 83514,
      "start": 837.9399999999999,
      "end": 841.14,
      "text": " If the tool doesn't exist and you want the tool,",
      "tokens": [
        50503,
        1002,
        262,
        2891,
        1595,
        470,
        2152,
        290,
        345,
        765,
        262,
        2891,
        11,
        50663
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06759433918171101,
      "compression_ratio": 1.815450643776824,
      "no_speech_prob": 0.0012195892632007599
    },
    {
      "id": 264,
      "seek": 83514,
      "start": 842.02,
      "end": 846.58,
      "text": " then you need to kind of know one language for making the tool",
      "tokens": [
        50707,
        788,
        345,
        761,
        284,
        1611,
        286,
        760,
        530,
        3303,
        329,
        1642,
        262,
        2891,
        50935
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06759433918171101,
      "compression_ratio": 1.815450643776824,
      "no_speech_prob": 0.0012195892632007599
    },
    {
      "id": 265,
      "seek": 83514,
      "start": 846.58,
      "end": 848.66,
      "text": " so that other people can use it",
      "tokens": [
        50935,
        523,
        326,
        584,
        661,
        460,
        779,
        340,
        51039
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06759433918171101,
      "compression_ratio": 1.815450643776824,
      "no_speech_prob": 0.0012195892632007599
    },
    {
      "id": 266,
      "seek": 83514,
      "start": 848.66,
      "end": 851.38,
      "text": " and another language for making tools so that other people want to use it.",
      "tokens": [
        51039,
        290,
        1194,
        3303,
        329,
        1642,
        4899,
        523,
        326,
        584,
        661,
        765,
        284,
        779,
        340,
        13,
        51175
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06759433918171101,
      "compression_ratio": 1.815450643776824,
      "no_speech_prob": 0.0012195892632007599
    },
    {
      "id": 267,
      "seek": 83514,
      "start": 852.5,
      "end": 856.9,
      "text": " And the way Julia presents itself is doing both.",
      "tokens": [
        51231,
        843,
        262,
        835,
        22300,
        10969,
        2346,
        318,
        1804,
        1111,
        13,
        51451
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06759433918171101,
      "compression_ratio": 1.815450643776824,
      "no_speech_prob": 0.0012195892632007599
    },
    {
      "id": 268,
      "seek": 83514,
      "start": 857.6999999999999,
      "end": 859.62,
      "text": " So what I want to do is kind of work through",
      "tokens": [
        51491,
        1406,
        644,
        314,
        765,
        284,
        466,
        318,
        1611,
        286,
        670,
        832,
        51587
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06759433918171101,
      "compression_ratio": 1.815450643776824,
      "no_speech_prob": 0.0012195892632007599
    },
    {
      "id": 269,
      "seek": 83514,
      "start": 860.5,
      "end": 863.9399999999999,
      "text": " the process of someone trying to build a new astronomy tool.",
      "tokens": [
        51631,
        262,
        1429,
        286,
        2130,
        2111,
        284,
        1382,
        257,
        649,
        37145,
        2891,
        13,
        51803
      ],
      "temperature": 0.0,
      "avg_logprob": -0.06759433918171101,
      "compression_ratio": 1.815450643776824,
      "no_speech_prob": 0.0012195892632007599
    },
    {
      "id": 270,
      "seek": 86514,
      "start": 865.46,
      "end": 868.26,
      "text": " This is obviously going to be somewhat of a contrived example,",
      "tokens": [
        50379,
        770,
        318,
        6189,
        1016,
        284,
        307,
        6454,
        286,
        257,
        542,
        36207,
        1672,
        11,
        50519
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16042413314183554,
      "compression_ratio": 1.5821596244131455,
      "no_speech_prob": 0.001261550118215382
    },
    {
      "id": 271,
      "seek": 86514,
      "start": 868.26,
      "end": 872.18,
      "text": " but just as an example, here's this thing.",
      "tokens": [
        50519,
        475,
        655,
        355,
        281,
        1672,
        11,
        994,
        338,
        428,
        1517,
        13,
        50715
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16042413314183554,
      "compression_ratio": 1.5821596244131455,
      "no_speech_prob": 0.001261550118215382
    },
    {
      "id": 272,
      "seek": 86514,
      "start": 872.74,
      "end": 876.58,
      "text": " Now, when you first start with it, you start having it be or whatever,",
      "tokens": [
        50743,
        2735,
        11,
        618,
        345,
        717,
        923,
        351,
        340,
        11,
        345,
        923,
        1719,
        340,
        307,
        393,
        4232,
        11,
        50935
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16042413314183554,
      "compression_ratio": 1.5821596244131455,
      "no_speech_prob": 0.001261550118215382
    },
    {
      "id": 273,
      "seek": 86514,
      "start": 876.58,
      "end": 880.74,
      "text": " and then from there you move on to it being a bit nicer and then blah blah blah.",
      "tokens": [
        50935,
        290,
        788,
        422,
        612,
        345,
        1445,
        319,
        284,
        340,
        852,
        257,
        1643,
        36597,
        290,
        788,
        33367,
        33367,
        33367,
        13,
        51143
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16042413314183554,
      "compression_ratio": 1.5821596244131455,
      "no_speech_prob": 0.001261550118215382
    },
    {
      "id": 274,
      "seek": 86514,
      "start": 880.74,
      "end": 881.78,
      "text": " Okay, that's a cool idea.",
      "tokens": [
        51143,
        16805,
        11,
        326,
        338,
        257,
        3608,
        2126,
        13,
        51195
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16042413314183554,
      "compression_ratio": 1.5821596244131455,
      "no_speech_prob": 0.001261550118215382
    },
    {
      "id": 275,
      "seek": 86514,
      "start": 883.14,
      "end": 887.54,
      "text": " Just about to pick Eve up, so I'm going to stop here.",
      "tokens": [
        51263,
        2329,
        546,
        284,
        2298,
        12882,
        510,
        11,
        523,
        314,
        1101,
        1016,
        284,
        2245,
        994,
        13,
        51483
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16042413314183554,
      "compression_ratio": 1.5821596244131455,
      "no_speech_prob": 0.001261550118215382
    }
  ],
  "language": "English"
}