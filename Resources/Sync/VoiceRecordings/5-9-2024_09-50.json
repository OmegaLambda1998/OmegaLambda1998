{
  "text": " Okay, so testing out the recording, ideally what happens is after this is recorded it gets sent over to the obsidian folder and then until you open obsidian that will back up and sync with the git, which means that these always go over there. And then I'll just have all of those in the, it would be in the attachments folder and I just need to figure out a way of then probably getting some kind of local LLM thing, like a local whisper alternative to do voice to text and then chuck that into a template of some kind, which I think should be fine. And I'll figure out the right way of doing that, but I think that's all going to work really well. Okay, so today I'm getting in and then I'm going to have the meeting at 10.30, Dingwan needs to zoom in, I haven't seen anyone else. And so if no one else responds saying that they're available I'll probably just tell Dingwan that we can't, so if no one else is there that's not really a point. Which is fine, things I really want to get done today, I have to email Ryan, that's non-negotiable, I want to email Saul and this is both to say are you coming in October and to say when your friends, your group meetings would love to start joining in and introducing myself. I think both of those things are very important. And then the last big thing I want to do is finish getting notes for all of the chapters and sections of the thesis so that I can actually have that filled up. I think that's, if I can do all of that then I'll feel good about today. The other thing that is a nice to have but not a have to have is going to end up being the getting a preview kind of thing for the Django DBAS database would be good as well if I can. Once I get that set up I'll be very happy. Yeah, I'm pretty happy with how Obsidian's looking at the moment, I don't think there's much more that needs to happen with that. And then, yeah, it's just trying to get writing done. I think probably what I should do is pick a day that is just writing day. Would be good. It would be nice to find some way of getting my calendar and my tasks to sync together. I'll be good to look into that. Because I want to be able to have things like the D&D stuff on there as well, but... I need to do more writing, that's the big thing. All this organizing is great but it's not getting writing done and I need to get writing done. Yeah, so for instance the Pippin paper, I don't know if that's got tasks and if it does I don't know if they've been properly defined. I'll have to look into that. I've got to figure out how to do the priorities better because at the moment a low priority is given the appointments tag, I believe, which isn't right. Lowest is a reminder, right, as in this can happen at some point but doesn't need to happen. Yeah, I might need to reorganize my things a bit. So we've got priority, I think, we want one symbol for priority and then a second symbol for whether it is due, whether it is scheduled and whether it is a recurring, right? I think those should be separate things because they can be like high priority recurring things and low priority recurring things, right? So I think, I think that's going to work better and then we'll just say by default, yeah it'd be good to have like different kinds of tasks, you know? So I've got like high priority tasks that are like do this shit today or make sure this shit is like getting done today and then as the tasks get lower and lower in priority that, yeah, priority should definitely be different to function or to event type, that's what I call it. So we'll have the priority of the task and then the type of event that the task is. So we could have a, you know, an appointment, do I call it an appointment? Yeah I mean there's a difference between like an event that I have to, where it's like this thing is occurring at this day and time, you need to do this, like unless you need to prepare for this more like this is something you need to do, that's one thing and then the other thing would be like this is something that needs to get done by a certain time, so that's a task. Yeah so we've got a task, we've got an event, then tasks have different priorities, yeah so we need, is it a task or an event is one thing, what is the priority is another thing and then is it due at a certain time, scheduled at a certain time and reoccurring, right? So the priority, task or event and then time constraints I guess would be the third thing. I think all of those things are going to be important, I'm sure there's a better way of doing the fucking sorting thing. I think probably what I want to do is make the sorting algorithm, like oh yeah the place that the task exists in should have a multiplicative effect so if it is in the medical cluster for instance, so by default you multiply the urgency by one, right? If it's in the medical cluster then we can bump up the urgency, the importance of it, so we multiply by like 1.5 for instance, or 1.1 or whatever right? And then, oh yeah we'll do 1.5, if it's in the academic one that can be like a 1.2 and then if it's in like the gaming one that can have a modifier of 0.9, so I think along those lines. And then what you'll do is like, if a supercluster has a modifier of 2, we'll say, and then within that you've got a cluster which has a modifier of 0.15, that should be, somehow I want that to be like, how does this thing relative to the other things within this change? So that's gonna be, you start at a base urgency of 1, right? The actual task is an urgency of 1, then if it's in a galaxy, you want to compare to other galaxies right? So if the galaxy has a modifier of 1.5, and another galaxy has a modifier of 1, then the urgency of the first galaxy is 1.5, okay. Then within that you've got a cluster, the cluster has a modifier of 2 for instance, so then it would be whatever the resulting urgency at the galaxy level is, you multiply that by the cluster level, so that would be 1.5 times 2 would give it a thing of 3, but then within the supercluster, it's got a modifier of fucking 0.1, and does that mean the final modifier should be 0.3? Final urgency should be 0.3, does that make sense? I think so, because that would mean that like, essentially no matter how important the object is within, well, so it's the question of, if I've said this supercluster is very important, so it has a positive modifier, do I then want to say a very unimportant task within this is more important than a very important task within an unimportant supercluster? And I think the answer is yes. And so what I think I will need to do is I essentially want to, there'll be multiplicative and there'll be additive I think. So for the medical cluster, within the medical cluster you can have multiplicative things, but you should then add, and the multiplicative things importantly should be between 0 and 2 I think. I think that should stop it from ever like, going out of hand and overtaking, because as far as I can tell, the maximum urgency that you get is somewhere below 10. I mean I can look at the urgency calculation actually, yeah, and then figure out what the double the maximum urgency is, so if the additive, if the additive modifier is greater than that double value, then we can guarantee that no matter how important or unimportant tasks are, this supercluster should be the most important, should have the biggest urgency. Yeah, that makes a lot of sense, okay. So that'd be awesome, that'd be really useful I think. We'll look into that, that's a cool thing. I'm gonna stop talking now and get back to driving.",
  "segments": [
    {
      "id": 0,
      "seek": 0,
      "start": 0.0,
      "end": 7.68,
      "text": " Okay, so testing out the recording, ideally what happens is after this is recorded it",
      "tokens": [
        50363,
        16805,
        11,
        523,
        4856,
        503,
        262,
        8296,
        11,
        30274,
        644,
        4325,
        318,
        706,
        428,
        318,
        6264,
        340,
        50747
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18740133138803336,
      "compression_ratio": 1.6706349206349207,
      "no_speech_prob": 0.12941916286945343
    },
    {
      "id": 1,
      "seek": 0,
      "start": 7.68,
      "end": 14.64,
      "text": " gets sent over to the obsidian folder and then until you open obsidian that will back",
      "tokens": [
        50747,
        3011,
        1908,
        625,
        284,
        262,
        10201,
        19825,
        9483,
        290,
        788,
        1566,
        345,
        1280,
        10201,
        19825,
        326,
        481,
        736,
        51095
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18740133138803336,
      "compression_ratio": 1.6706349206349207,
      "no_speech_prob": 0.12941916286945343
    },
    {
      "id": 2,
      "seek": 0,
      "start": 14.64,
      "end": 18.84,
      "text": " up and sync with the git, which means that these always go over there.",
      "tokens": [
        51095,
        510,
        290,
        17510,
        351,
        262,
        17606,
        11,
        543,
        1724,
        326,
        777,
        1464,
        467,
        625,
        612,
        13,
        51305
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18740133138803336,
      "compression_ratio": 1.6706349206349207,
      "no_speech_prob": 0.12941916286945343
    },
    {
      "id": 3,
      "seek": 0,
      "start": 18.84,
      "end": 23.080000000000002,
      "text": " And then I'll just have all of those in the, it would be in the attachments folder and",
      "tokens": [
        51305,
        843,
        788,
        314,
        1183,
        655,
        423,
        477,
        286,
        883,
        287,
        262,
        11,
        340,
        561,
        307,
        287,
        262,
        32161,
        9483,
        290,
        51517
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18740133138803336,
      "compression_ratio": 1.6706349206349207,
      "no_speech_prob": 0.12941916286945343
    },
    {
      "id": 4,
      "seek": 0,
      "start": 23.080000000000002,
      "end": 29.52,
      "text": " I just need to figure out a way of then probably getting some kind of local LLM thing, like",
      "tokens": [
        51517,
        314,
        655,
        761,
        284,
        3785,
        503,
        257,
        835,
        286,
        788,
        2192,
        1972,
        617,
        1611,
        286,
        1957,
        27140,
        44,
        1517,
        11,
        588,
        51839
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18740133138803336,
      "compression_ratio": 1.6706349206349207,
      "no_speech_prob": 0.12941916286945343
    },
    {
      "id": 5,
      "seek": 2952,
      "start": 29.52,
      "end": 39.96,
      "text": " a local whisper alternative to do voice to text and then chuck that into a template of",
      "tokens": [
        50363,
        257,
        1957,
        31992,
        5559,
        284,
        466,
        3809,
        284,
        2420,
        290,
        788,
        20539,
        326,
        656,
        257,
        11055,
        286,
        50885
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1838799278334816,
      "compression_ratio": 1.5407725321888412,
      "no_speech_prob": 0.006713757757097483
    },
    {
      "id": 6,
      "seek": 2952,
      "start": 39.96,
      "end": 43.84,
      "text": " some kind, which I think should be fine.",
      "tokens": [
        50885,
        617,
        1611,
        11,
        543,
        314,
        892,
        815,
        307,
        3734,
        13,
        51079
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1838799278334816,
      "compression_ratio": 1.5407725321888412,
      "no_speech_prob": 0.006713757757097483
    },
    {
      "id": 7,
      "seek": 2952,
      "start": 43.84,
      "end": 47.08,
      "text": " And I'll figure out the right way of doing that, but I think that's all going to work",
      "tokens": [
        51079,
        843,
        314,
        1183,
        3785,
        503,
        262,
        826,
        835,
        286,
        1804,
        326,
        11,
        475,
        314,
        892,
        326,
        338,
        477,
        1016,
        284,
        670,
        51241
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1838799278334816,
      "compression_ratio": 1.5407725321888412,
      "no_speech_prob": 0.006713757757097483
    },
    {
      "id": 8,
      "seek": 2952,
      "start": 47.08,
      "end": 48.08,
      "text": " really well.",
      "tokens": [
        51241,
        1107,
        880,
        13,
        51291
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1838799278334816,
      "compression_ratio": 1.5407725321888412,
      "no_speech_prob": 0.006713757757097483
    },
    {
      "id": 9,
      "seek": 2952,
      "start": 48.08,
      "end": 55.32,
      "text": " Okay, so today I'm getting in and then I'm going to have the meeting at 10.30, Dingwan",
      "tokens": [
        51291,
        16805,
        11,
        523,
        1909,
        314,
        1101,
        1972,
        287,
        290,
        788,
        314,
        1101,
        1016,
        284,
        423,
        262,
        3249,
        379,
        838,
        13,
        1270,
        11,
        46980,
        8149,
        51653
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1838799278334816,
      "compression_ratio": 1.5407725321888412,
      "no_speech_prob": 0.006713757757097483
    },
    {
      "id": 10,
      "seek": 2952,
      "start": 55.32,
      "end": 59.08,
      "text": " needs to zoom in, I haven't seen anyone else.",
      "tokens": [
        51653,
        2476,
        284,
        19792,
        287,
        11,
        314,
        4398,
        470,
        1775,
        2687,
        2073,
        13,
        51841
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1838799278334816,
      "compression_ratio": 1.5407725321888412,
      "no_speech_prob": 0.006713757757097483
    },
    {
      "id": 11,
      "seek": 5908,
      "start": 59.08,
      "end": 63.0,
      "text": " And so if no one else responds saying that they're available I'll probably just tell",
      "tokens": [
        50363,
        843,
        523,
        611,
        645,
        530,
        2073,
        20067,
        2282,
        326,
        484,
        821,
        1695,
        314,
        1183,
        2192,
        655,
        1560,
        50559
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16641416047748767,
      "compression_ratio": 1.6111111111111112,
      "no_speech_prob": 0.06197642534971237
    },
    {
      "id": 12,
      "seek": 5908,
      "start": 63.0,
      "end": 68.48,
      "text": " Dingwan that we can't, so if no one else is there that's not really a point.",
      "tokens": [
        50559,
        46980,
        8149,
        326,
        356,
        460,
        470,
        11,
        523,
        611,
        645,
        530,
        2073,
        318,
        612,
        326,
        338,
        407,
        1107,
        257,
        966,
        13,
        50833
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16641416047748767,
      "compression_ratio": 1.6111111111111112,
      "no_speech_prob": 0.06197642534971237
    },
    {
      "id": 13,
      "seek": 5908,
      "start": 68.48,
      "end": 78.86,
      "text": " Which is fine, things I really want to get done today, I have to email Ryan, that's non-negotiable,",
      "tokens": [
        50833,
        9022,
        318,
        3734,
        11,
        1243,
        314,
        1107,
        765,
        284,
        651,
        1760,
        1909,
        11,
        314,
        423,
        284,
        3053,
        6047,
        11,
        326,
        338,
        1729,
        12,
        12480,
        313,
        3379,
        11,
        51352
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16641416047748767,
      "compression_ratio": 1.6111111111111112,
      "no_speech_prob": 0.06197642534971237
    },
    {
      "id": 14,
      "seek": 5908,
      "start": 78.86,
      "end": 87.24,
      "text": " I want to email Saul and this is both to say are you coming in October and to say when",
      "tokens": [
        51352,
        314,
        765,
        284,
        3053,
        31603,
        290,
        428,
        318,
        1111,
        284,
        910,
        389,
        345,
        2406,
        287,
        3267,
        290,
        284,
        910,
        618,
        51771
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16641416047748767,
      "compression_ratio": 1.6111111111111112,
      "no_speech_prob": 0.06197642534971237
    },
    {
      "id": 15,
      "seek": 8724,
      "start": 87.24,
      "end": 92.16,
      "text": " your friends, your group meetings would love to start joining in and introducing myself.",
      "tokens": [
        50363,
        534,
        2460,
        11,
        534,
        1448,
        8292,
        561,
        1842,
        284,
        923,
        9679,
        287,
        290,
        16118,
        3589,
        13,
        50609
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16588215205980383,
      "compression_ratio": 1.6371681415929205,
      "no_speech_prob": 0.9802641868591309
    },
    {
      "id": 16,
      "seek": 8724,
      "start": 92.16,
      "end": 95.72,
      "text": " I think both of those things are very important.",
      "tokens": [
        50609,
        314,
        892,
        1111,
        286,
        883,
        1243,
        389,
        845,
        1593,
        13,
        50787
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16588215205980383,
      "compression_ratio": 1.6371681415929205,
      "no_speech_prob": 0.9802641868591309
    },
    {
      "id": 17,
      "seek": 8724,
      "start": 95.72,
      "end": 104.11999999999999,
      "text": " And then the last big thing I want to do is finish getting notes for all of the chapters",
      "tokens": [
        50787,
        843,
        788,
        262,
        938,
        1263,
        1517,
        314,
        765,
        284,
        466,
        318,
        5461,
        1972,
        4710,
        329,
        477,
        286,
        262,
        15754,
        51207
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16588215205980383,
      "compression_ratio": 1.6371681415929205,
      "no_speech_prob": 0.9802641868591309
    },
    {
      "id": 18,
      "seek": 8724,
      "start": 104.11999999999999,
      "end": 108.03999999999999,
      "text": " and sections of the thesis so that I can actually have that filled up.",
      "tokens": [
        51207,
        290,
        9004,
        286,
        262,
        21554,
        523,
        326,
        314,
        460,
        1682,
        423,
        326,
        5901,
        510,
        13,
        51403
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16588215205980383,
      "compression_ratio": 1.6371681415929205,
      "no_speech_prob": 0.9802641868591309
    },
    {
      "id": 19,
      "seek": 8724,
      "start": 108.03999999999999,
      "end": 114.47999999999999,
      "text": " I think that's, if I can do all of that then I'll feel good about today.",
      "tokens": [
        51403,
        314,
        892,
        326,
        338,
        11,
        611,
        314,
        460,
        466,
        477,
        286,
        326,
        788,
        314,
        1183,
        1254,
        922,
        546,
        1909,
        13,
        51725
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16588215205980383,
      "compression_ratio": 1.6371681415929205,
      "no_speech_prob": 0.9802641868591309
    },
    {
      "id": 20,
      "seek": 11448,
      "start": 114.48,
      "end": 119.48,
      "text": " The other thing that is a nice to have but not a have to have is going to end up being",
      "tokens": [
        50363,
        383,
        584,
        1517,
        326,
        318,
        257,
        3621,
        284,
        423,
        475,
        407,
        257,
        423,
        284,
        423,
        318,
        1016,
        284,
        886,
        510,
        852,
        50613
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21371217791953784,
      "compression_ratio": 1.5169082125603865,
      "no_speech_prob": 0.03046094998717308
    },
    {
      "id": 21,
      "seek": 11448,
      "start": 119.48,
      "end": 133.32,
      "text": " the getting a preview kind of thing for the Django DBAS database would be good as well",
      "tokens": [
        50613,
        262,
        1972,
        257,
        12714,
        1611,
        286,
        1517,
        329,
        262,
        37770,
        20137,
        1921,
        6831,
        561,
        307,
        922,
        355,
        880,
        51305
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21371217791953784,
      "compression_ratio": 1.5169082125603865,
      "no_speech_prob": 0.03046094998717308
    },
    {
      "id": 22,
      "seek": 11448,
      "start": 133.32,
      "end": 135.32,
      "text": " if I can.",
      "tokens": [
        51305,
        611,
        314,
        460,
        13,
        51405
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21371217791953784,
      "compression_ratio": 1.5169082125603865,
      "no_speech_prob": 0.03046094998717308
    },
    {
      "id": 23,
      "seek": 11448,
      "start": 135.32,
      "end": 138.32,
      "text": " Once I get that set up I'll be very happy.",
      "tokens": [
        51405,
        4874,
        314,
        651,
        326,
        900,
        510,
        314,
        1183,
        307,
        845,
        3772,
        13,
        51555
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21371217791953784,
      "compression_ratio": 1.5169082125603865,
      "no_speech_prob": 0.03046094998717308
    },
    {
      "id": 24,
      "seek": 11448,
      "start": 138.32,
      "end": 143.92000000000002,
      "text": " Yeah, I'm pretty happy with how Obsidian's looking at the moment, I don't think there's",
      "tokens": [
        51555,
        9425,
        11,
        314,
        1101,
        2495,
        3772,
        351,
        703,
        11086,
        19825,
        338,
        2045,
        379,
        262,
        2589,
        11,
        314,
        836,
        470,
        892,
        612,
        338,
        51835
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21371217791953784,
      "compression_ratio": 1.5169082125603865,
      "no_speech_prob": 0.03046094998717308
    },
    {
      "id": 25,
      "seek": 14392,
      "start": 143.92,
      "end": 148.44,
      "text": " much more that needs to happen with that.",
      "tokens": [
        50363,
        881,
        517,
        326,
        2476,
        284,
        1645,
        351,
        326,
        13,
        50589
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19033602396647134,
      "compression_ratio": 1.5027624309392265,
      "no_speech_prob": 0.9586982727050781
    },
    {
      "id": 26,
      "seek": 14392,
      "start": 148.44,
      "end": 153.27999999999997,
      "text": " And then, yeah, it's just trying to get writing done.",
      "tokens": [
        50589,
        843,
        788,
        11,
        10194,
        11,
        340,
        338,
        655,
        2111,
        284,
        651,
        3597,
        1760,
        13,
        50831
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19033602396647134,
      "compression_ratio": 1.5027624309392265,
      "no_speech_prob": 0.9586982727050781
    },
    {
      "id": 27,
      "seek": 14392,
      "start": 153.27999999999997,
      "end": 161.79999999999998,
      "text": " I think probably what I should do is pick a day that is just writing day.",
      "tokens": [
        50831,
        314,
        892,
        2192,
        644,
        314,
        815,
        466,
        318,
        2298,
        257,
        1110,
        326,
        318,
        655,
        3597,
        1110,
        13,
        51257
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19033602396647134,
      "compression_ratio": 1.5027624309392265,
      "no_speech_prob": 0.9586982727050781
    },
    {
      "id": 28,
      "seek": 14392,
      "start": 161.79999999999998,
      "end": 162.79999999999998,
      "text": " Would be good.",
      "tokens": [
        51257,
        10928,
        307,
        922,
        13,
        51307
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19033602396647134,
      "compression_ratio": 1.5027624309392265,
      "no_speech_prob": 0.9586982727050781
    },
    {
      "id": 29,
      "seek": 14392,
      "start": 162.79999999999998,
      "end": 169.56,
      "text": " It would be nice to find some way of getting my calendar and my tasks to sync together.",
      "tokens": [
        51307,
        632,
        561,
        307,
        3621,
        284,
        1064,
        617,
        835,
        286,
        1972,
        616,
        11845,
        290,
        616,
        8861,
        284,
        17510,
        1978,
        13,
        51645
      ],
      "temperature": 0.0,
      "avg_logprob": -0.19033602396647134,
      "compression_ratio": 1.5027624309392265,
      "no_speech_prob": 0.9586982727050781
    },
    {
      "id": 30,
      "seek": 16956,
      "start": 169.56,
      "end": 173.96,
      "text": " I'll be good to look into that.",
      "tokens": [
        50363,
        314,
        1183,
        307,
        922,
        284,
        804,
        656,
        326,
        13,
        50583
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26931433928640264,
      "compression_ratio": 1.5568862275449102,
      "no_speech_prob": 0.6659474968910217
    },
    {
      "id": 31,
      "seek": 16956,
      "start": 173.96,
      "end": 182.08,
      "text": " Because I want to be able to have things like the D&D stuff on there as well, but...",
      "tokens": [
        50583,
        4362,
        314,
        765,
        284,
        307,
        1498,
        284,
        423,
        1243,
        588,
        262,
        360,
        5,
        35,
        3404,
        319,
        612,
        355,
        880,
        11,
        475,
        986,
        50989
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26931433928640264,
      "compression_ratio": 1.5568862275449102,
      "no_speech_prob": 0.6659474968910217
    },
    {
      "id": 32,
      "seek": 16956,
      "start": 182.08,
      "end": 189.0,
      "text": " I need to do more writing, that's the big thing.",
      "tokens": [
        50989,
        314,
        761,
        284,
        466,
        517,
        3597,
        11,
        326,
        338,
        262,
        1263,
        1517,
        13,
        51335
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26931433928640264,
      "compression_ratio": 1.5568862275449102,
      "no_speech_prob": 0.6659474968910217
    },
    {
      "id": 33,
      "seek": 16956,
      "start": 189.0,
      "end": 193.6,
      "text": " All this organizing is great but it's not getting writing done and I need to get writing",
      "tokens": [
        51335,
        1439,
        428,
        16924,
        318,
        1049,
        475,
        340,
        338,
        407,
        1972,
        3597,
        1760,
        290,
        314,
        761,
        284,
        651,
        3597,
        51565
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26931433928640264,
      "compression_ratio": 1.5568862275449102,
      "no_speech_prob": 0.6659474968910217
    },
    {
      "id": 34,
      "seek": 16956,
      "start": 193.6,
      "end": 194.6,
      "text": " done.",
      "tokens": [
        51565,
        1760,
        13,
        51615
      ],
      "temperature": 0.0,
      "avg_logprob": -0.26931433928640264,
      "compression_ratio": 1.5568862275449102,
      "no_speech_prob": 0.6659474968910217
    },
    {
      "id": 35,
      "seek": 19460,
      "start": 194.6,
      "end": 203.07999999999998,
      "text": " Yeah, so for instance the Pippin paper, I don't know if that's got tasks and if it does",
      "tokens": [
        50363,
        9425,
        11,
        523,
        329,
        4554,
        262,
        350,
        3974,
        259,
        3348,
        11,
        314,
        836,
        470,
        760,
        611,
        326,
        338,
        1392,
        8861,
        290,
        611,
        340,
        857,
        50787
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21806040063368537,
      "compression_ratio": 1.6491935483870968,
      "no_speech_prob": 0.7549789547920227
    },
    {
      "id": 36,
      "seek": 19460,
      "start": 203.07999999999998,
      "end": 205.07999999999998,
      "text": " I don't know if they've been properly defined.",
      "tokens": [
        50787,
        314,
        836,
        470,
        760,
        611,
        484,
        1053,
        587,
        6105,
        5447,
        13,
        50887
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21806040063368537,
      "compression_ratio": 1.6491935483870968,
      "no_speech_prob": 0.7549789547920227
    },
    {
      "id": 37,
      "seek": 19460,
      "start": 205.07999999999998,
      "end": 206.07999999999998,
      "text": " I'll have to look into that.",
      "tokens": [
        50887,
        314,
        1183,
        423,
        284,
        804,
        656,
        326,
        13,
        50937
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21806040063368537,
      "compression_ratio": 1.6491935483870968,
      "no_speech_prob": 0.7549789547920227
    },
    {
      "id": 38,
      "seek": 19460,
      "start": 206.07999999999998,
      "end": 210.32,
      "text": " I've got to figure out how to do the priorities better because at the moment a low priority",
      "tokens": [
        50937,
        314,
        1053,
        1392,
        284,
        3785,
        503,
        703,
        284,
        466,
        262,
        15369,
        1365,
        780,
        379,
        262,
        2589,
        257,
        1877,
        8475,
        51149
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21806040063368537,
      "compression_ratio": 1.6491935483870968,
      "no_speech_prob": 0.7549789547920227
    },
    {
      "id": 39,
      "seek": 19460,
      "start": 210.32,
      "end": 216.79999999999998,
      "text": " is given the appointments tag, I believe, which isn't right.",
      "tokens": [
        51149,
        318,
        1813,
        262,
        23976,
        7621,
        11,
        314,
        1975,
        11,
        543,
        2125,
        470,
        826,
        13,
        51473
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21806040063368537,
      "compression_ratio": 1.6491935483870968,
      "no_speech_prob": 0.7549789547920227
    },
    {
      "id": 40,
      "seek": 19460,
      "start": 216.79999999999998,
      "end": 224.35999999999999,
      "text": " Lowest is a reminder, right, as in this can happen at some point but doesn't need to happen.",
      "tokens": [
        51473,
        7754,
        395,
        318,
        257,
        15438,
        11,
        826,
        11,
        355,
        287,
        428,
        460,
        1645,
        379,
        617,
        966,
        475,
        1595,
        470,
        761,
        284,
        1645,
        13,
        51851
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21806040063368537,
      "compression_ratio": 1.6491935483870968,
      "no_speech_prob": 0.7549789547920227
    },
    {
      "id": 41,
      "seek": 22436,
      "start": 224.36,
      "end": 227.0,
      "text": " Yeah, I might need to reorganize my things a bit.",
      "tokens": [
        50363,
        9425,
        11,
        314,
        1244,
        761,
        284,
        35459,
        1096,
        616,
        1243,
        257,
        1643,
        13,
        50495
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2240706357088956,
      "compression_ratio": 1.8232323232323233,
      "no_speech_prob": 0.025769872590899467
    },
    {
      "id": 42,
      "seek": 22436,
      "start": 227.0,
      "end": 237.18,
      "text": " So we've got priority, I think, we want one symbol for priority and then a second symbol",
      "tokens": [
        50495,
        1406,
        356,
        1053,
        1392,
        8475,
        11,
        314,
        892,
        11,
        356,
        765,
        530,
        6194,
        329,
        8475,
        290,
        788,
        257,
        1218,
        6194,
        51004
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2240706357088956,
      "compression_ratio": 1.8232323232323233,
      "no_speech_prob": 0.025769872590899467
    },
    {
      "id": 43,
      "seek": 22436,
      "start": 237.18,
      "end": 243.52,
      "text": " for whether it is due, whether it is scheduled and whether it is a recurring, right?",
      "tokens": [
        51004,
        329,
        1771,
        340,
        318,
        2233,
        11,
        1771,
        340,
        318,
        7530,
        290,
        1771,
        340,
        318,
        257,
        24824,
        11,
        826,
        30,
        51321
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2240706357088956,
      "compression_ratio": 1.8232323232323233,
      "no_speech_prob": 0.025769872590899467
    },
    {
      "id": 44,
      "seek": 22436,
      "start": 243.52,
      "end": 251.52,
      "text": " I think those should be separate things because they can be like high priority recurring things",
      "tokens": [
        51321,
        314,
        892,
        883,
        815,
        307,
        4553,
        1243,
        780,
        484,
        460,
        307,
        588,
        1029,
        8475,
        24824,
        1243,
        51721
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2240706357088956,
      "compression_ratio": 1.8232323232323233,
      "no_speech_prob": 0.025769872590899467
    },
    {
      "id": 45,
      "seek": 22436,
      "start": 251.52,
      "end": 254.32000000000002,
      "text": " and low priority recurring things, right?",
      "tokens": [
        51721,
        290,
        1877,
        8475,
        24824,
        1243,
        11,
        826,
        30,
        51861
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2240706357088956,
      "compression_ratio": 1.8232323232323233,
      "no_speech_prob": 0.025769872590899467
    },
    {
      "id": 46,
      "seek": 25432,
      "start": 254.32,
      "end": 268.88,
      "text": " So I think, I think that's going to work better and then we'll just say by default, yeah it'd",
      "tokens": [
        50363,
        1406,
        314,
        892,
        11,
        314,
        892,
        326,
        338,
        1016,
        284,
        670,
        1365,
        290,
        788,
        356,
        1183,
        655,
        910,
        416,
        4277,
        11,
        10194,
        340,
        1549,
        51091
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21871261137077608,
      "compression_ratio": 1.6701030927835052,
      "no_speech_prob": 0.01683422364294529
    },
    {
      "id": 47,
      "seek": 25432,
      "start": 268.88,
      "end": 272.15999999999997,
      "text": " be good to have like different kinds of tasks, you know?",
      "tokens": [
        51091,
        307,
        922,
        284,
        423,
        588,
        1180,
        6982,
        286,
        8861,
        11,
        345,
        760,
        30,
        51255
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21871261137077608,
      "compression_ratio": 1.6701030927835052,
      "no_speech_prob": 0.01683422364294529
    },
    {
      "id": 48,
      "seek": 25432,
      "start": 272.15999999999997,
      "end": 278.48,
      "text": " So I've got like high priority tasks that are like do this shit today or make sure this",
      "tokens": [
        51255,
        1406,
        314,
        1053,
        1392,
        588,
        1029,
        8475,
        8861,
        326,
        389,
        588,
        466,
        428,
        7510,
        1909,
        393,
        787,
        1654,
        428,
        51571
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21871261137077608,
      "compression_ratio": 1.6701030927835052,
      "no_speech_prob": 0.01683422364294529
    },
    {
      "id": 49,
      "seek": 25432,
      "start": 278.48,
      "end": 284.03999999999996,
      "text": " shit is like getting done today and then as the tasks get lower and lower in priority",
      "tokens": [
        51571,
        7510,
        318,
        588,
        1972,
        1760,
        1909,
        290,
        788,
        355,
        262,
        8861,
        651,
        2793,
        290,
        2793,
        287,
        8475,
        51849
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21871261137077608,
      "compression_ratio": 1.6701030927835052,
      "no_speech_prob": 0.01683422364294529
    },
    {
      "id": 50,
      "seek": 28404,
      "start": 284.04,
      "end": 297.96000000000004,
      "text": " that, yeah, priority should definitely be different to function or to event type, that's",
      "tokens": [
        50363,
        326,
        11,
        10194,
        11,
        8475,
        815,
        4753,
        307,
        1180,
        284,
        2163,
        393,
        284,
        1785,
        2099,
        11,
        326,
        338,
        51059
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2462168113858092,
      "compression_ratio": 1.4573643410852712,
      "no_speech_prob": 0.07966713607311249
    },
    {
      "id": 51,
      "seek": 28404,
      "start": 297.96000000000004,
      "end": 298.96000000000004,
      "text": " what I call it.",
      "tokens": [
        51059,
        644,
        314,
        869,
        340,
        13,
        51109
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2462168113858092,
      "compression_ratio": 1.4573643410852712,
      "no_speech_prob": 0.07966713607311249
    },
    {
      "id": 52,
      "seek": 28404,
      "start": 298.96000000000004,
      "end": 306.24,
      "text": " So we'll have the priority of the task and then the type of event that the task is.",
      "tokens": [
        51109,
        1406,
        356,
        1183,
        423,
        262,
        8475,
        286,
        262,
        4876,
        290,
        788,
        262,
        2099,
        286,
        1785,
        326,
        262,
        4876,
        318,
        13,
        51473
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2462168113858092,
      "compression_ratio": 1.4573643410852712,
      "no_speech_prob": 0.07966713607311249
    },
    {
      "id": 53,
      "seek": 30624,
      "start": 306.24,
      "end": 315.76,
      "text": " So we could have a, you know, an appointment, do I call it an appointment?",
      "tokens": [
        50363,
        1406,
        356,
        714,
        423,
        257,
        11,
        345,
        760,
        11,
        281,
        12557,
        11,
        466,
        314,
        869,
        340,
        281,
        12557,
        30,
        50839
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16271493287213082,
      "compression_ratio": 1.8922413793103448,
      "no_speech_prob": 0.5729697942733765
    },
    {
      "id": 54,
      "seek": 30624,
      "start": 315.76,
      "end": 319.92,
      "text": " Yeah I mean there's a difference between like an event that I have to, where it's like this",
      "tokens": [
        50839,
        9425,
        314,
        1612,
        612,
        338,
        257,
        3580,
        1022,
        588,
        281,
        1785,
        326,
        314,
        423,
        284,
        11,
        810,
        340,
        338,
        588,
        428,
        51047
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16271493287213082,
      "compression_ratio": 1.8922413793103448,
      "no_speech_prob": 0.5729697942733765
    },
    {
      "id": 55,
      "seek": 30624,
      "start": 319.92,
      "end": 327.0,
      "text": " thing is occurring at this day and time, you need to do this, like unless you need to prepare",
      "tokens": [
        51047,
        1517,
        318,
        14963,
        379,
        428,
        1110,
        290,
        640,
        11,
        345,
        761,
        284,
        466,
        428,
        11,
        588,
        4556,
        345,
        761,
        284,
        8335,
        51401
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16271493287213082,
      "compression_ratio": 1.8922413793103448,
      "no_speech_prob": 0.5729697942733765
    },
    {
      "id": 56,
      "seek": 30624,
      "start": 327.0,
      "end": 331.08,
      "text": " for this more like this is something you need to do, that's one thing and then the other",
      "tokens": [
        51401,
        329,
        428,
        517,
        588,
        428,
        318,
        1223,
        345,
        761,
        284,
        466,
        11,
        326,
        338,
        530,
        1517,
        290,
        788,
        262,
        584,
        51605
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16271493287213082,
      "compression_ratio": 1.8922413793103448,
      "no_speech_prob": 0.5729697942733765
    },
    {
      "id": 57,
      "seek": 30624,
      "start": 331.08,
      "end": 335.40000000000003,
      "text": " thing would be like this is something that needs to get done by a certain time, so that's",
      "tokens": [
        51605,
        1517,
        561,
        307,
        588,
        428,
        318,
        1223,
        326,
        2476,
        284,
        651,
        1760,
        416,
        257,
        1728,
        640,
        11,
        523,
        326,
        338,
        51821
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16271493287213082,
      "compression_ratio": 1.8922413793103448,
      "no_speech_prob": 0.5729697942733765
    },
    {
      "id": 58,
      "seek": 33540,
      "start": 335.4,
      "end": 336.4,
      "text": " a task.",
      "tokens": [
        50363,
        257,
        4876,
        13,
        50413
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16974445489736703,
      "compression_ratio": 1.7628205128205128,
      "no_speech_prob": 0.9790443778038025
    },
    {
      "id": 59,
      "seek": 33540,
      "start": 336.4,
      "end": 344.35999999999996,
      "text": " Yeah so we've got a task, we've got an event, then tasks have different priorities, yeah",
      "tokens": [
        50413,
        9425,
        523,
        356,
        1053,
        1392,
        257,
        4876,
        11,
        356,
        1053,
        1392,
        281,
        1785,
        11,
        788,
        8861,
        423,
        1180,
        15369,
        11,
        10194,
        50811
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16974445489736703,
      "compression_ratio": 1.7628205128205128,
      "no_speech_prob": 0.9790443778038025
    },
    {
      "id": 60,
      "seek": 33540,
      "start": 344.35999999999996,
      "end": 353.76,
      "text": " so we need, is it a task or an event is one thing, what is the priority is another thing",
      "tokens": [
        50811,
        523,
        356,
        761,
        11,
        318,
        340,
        257,
        4876,
        393,
        281,
        1785,
        318,
        530,
        1517,
        11,
        644,
        318,
        262,
        8475,
        318,
        1194,
        1517,
        51281
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16974445489736703,
      "compression_ratio": 1.7628205128205128,
      "no_speech_prob": 0.9790443778038025
    },
    {
      "id": 61,
      "seek": 33540,
      "start": 353.76,
      "end": 363.15999999999997,
      "text": " and then is it due at a certain time, scheduled at a certain time and reoccurring, right?",
      "tokens": [
        51281,
        290,
        788,
        318,
        340,
        2233,
        379,
        257,
        1728,
        640,
        11,
        7530,
        379,
        257,
        1728,
        640,
        290,
        302,
        13966,
        14924,
        11,
        826,
        30,
        51751
      ],
      "temperature": 0.0,
      "avg_logprob": -0.16974445489736703,
      "compression_ratio": 1.7628205128205128,
      "no_speech_prob": 0.9790443778038025
    },
    {
      "id": 62,
      "seek": 36316,
      "start": 363.16,
      "end": 375.04,
      "text": " So the priority, task or event and then time constraints I guess would be the third thing.",
      "tokens": [
        50363,
        1406,
        262,
        8475,
        11,
        4876,
        393,
        1785,
        290,
        788,
        640,
        17778,
        314,
        4724,
        561,
        307,
        262,
        2368,
        1517,
        13,
        50957
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13452704056449558,
      "compression_ratio": 1.37984496124031,
      "no_speech_prob": 0.059747181832790375
    },
    {
      "id": 63,
      "seek": 36316,
      "start": 375.04,
      "end": 383.92,
      "text": " I think all of those things are going to be important, I'm sure there's a better way of",
      "tokens": [
        50957,
        314,
        892,
        477,
        286,
        883,
        1243,
        389,
        1016,
        284,
        307,
        1593,
        11,
        314,
        1101,
        1654,
        612,
        338,
        257,
        1365,
        835,
        286,
        51401
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13452704056449558,
      "compression_ratio": 1.37984496124031,
      "no_speech_prob": 0.059747181832790375
    },
    {
      "id": 64,
      "seek": 38392,
      "start": 383.92,
      "end": 397.48,
      "text": " doing the fucking sorting thing.",
      "tokens": [
        50363,
        1804,
        262,
        9372,
        29407,
        1517,
        13,
        51041
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14917150827554557,
      "compression_ratio": 1.4896551724137932,
      "no_speech_prob": 0.2711470425128937
    },
    {
      "id": 65,
      "seek": 38392,
      "start": 397.48,
      "end": 405.88,
      "text": " I think probably what I want to do is make the sorting algorithm, like oh yeah the place",
      "tokens": [
        51041,
        314,
        892,
        2192,
        644,
        314,
        765,
        284,
        466,
        318,
        787,
        262,
        29407,
        11862,
        11,
        588,
        11752,
        10194,
        262,
        1295,
        51461
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14917150827554557,
      "compression_ratio": 1.4896551724137932,
      "no_speech_prob": 0.2711470425128937
    },
    {
      "id": 66,
      "seek": 38392,
      "start": 405.88,
      "end": 413.84000000000003,
      "text": " that the task exists in should have a multiplicative effect so if it is in the medical cluster",
      "tokens": [
        51461,
        326,
        262,
        4876,
        7160,
        287,
        815,
        423,
        257,
        15082,
        43058,
        1245,
        523,
        611,
        340,
        318,
        287,
        262,
        3315,
        13946,
        51859
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14917150827554557,
      "compression_ratio": 1.4896551724137932,
      "no_speech_prob": 0.2711470425128937
    },
    {
      "id": 67,
      "seek": 41384,
      "start": 413.84,
      "end": 419.61999999999995,
      "text": " for instance, so by default you multiply the urgency by one, right?",
      "tokens": [
        50363,
        329,
        4554,
        11,
        523,
        416,
        4277,
        345,
        29162,
        262,
        25615,
        416,
        530,
        11,
        826,
        30,
        50652
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15922549619513043,
      "compression_ratio": 1.74235807860262,
      "no_speech_prob": 0.8083164691925049
    },
    {
      "id": 68,
      "seek": 41384,
      "start": 419.61999999999995,
      "end": 425.44,
      "text": " If it's in the medical cluster then we can bump up the urgency, the importance of it,",
      "tokens": [
        50652,
        1002,
        340,
        338,
        287,
        262,
        3315,
        13946,
        788,
        356,
        460,
        13852,
        510,
        262,
        25615,
        11,
        262,
        6817,
        286,
        340,
        11,
        50943
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15922549619513043,
      "compression_ratio": 1.74235807860262,
      "no_speech_prob": 0.8083164691925049
    },
    {
      "id": 69,
      "seek": 41384,
      "start": 425.44,
      "end": 431.64,
      "text": " so we multiply by like 1.5 for instance, or 1.1 or whatever right?",
      "tokens": [
        50943,
        523,
        356,
        29162,
        416,
        588,
        352,
        13,
        20,
        329,
        4554,
        11,
        393,
        352,
        13,
        16,
        393,
        4232,
        826,
        30,
        51253
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15922549619513043,
      "compression_ratio": 1.74235807860262,
      "no_speech_prob": 0.8083164691925049
    },
    {
      "id": 70,
      "seek": 41384,
      "start": 431.64,
      "end": 437.96,
      "text": " And then, oh yeah we'll do 1.5, if it's in the academic one that can be like a 1.2 and",
      "tokens": [
        51253,
        843,
        788,
        11,
        11752,
        10194,
        356,
        1183,
        466,
        352,
        13,
        20,
        11,
        611,
        340,
        338,
        287,
        262,
        8233,
        530,
        326,
        460,
        307,
        588,
        257,
        352,
        13,
        17,
        290,
        51569
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15922549619513043,
      "compression_ratio": 1.74235807860262,
      "no_speech_prob": 0.8083164691925049
    },
    {
      "id": 71,
      "seek": 41384,
      "start": 437.96,
      "end": 442.23999999999995,
      "text": " then if it's in like the gaming one that can have a modifier of 0.9, so I think along those",
      "tokens": [
        51569,
        788,
        611,
        340,
        338,
        287,
        588,
        262,
        7776,
        530,
        326,
        460,
        423,
        257,
        23157,
        286,
        657,
        13,
        24,
        11,
        523,
        314,
        892,
        1863,
        883,
        51783
      ],
      "temperature": 0.0,
      "avg_logprob": -0.15922549619513043,
      "compression_ratio": 1.74235807860262,
      "no_speech_prob": 0.8083164691925049
    },
    {
      "id": 72,
      "seek": 44224,
      "start": 442.24,
      "end": 443.24,
      "text": " lines.",
      "tokens": [
        50363,
        3951,
        13,
        50413
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14037834803263347,
      "compression_ratio": 1.4485294117647058,
      "no_speech_prob": 0.955777645111084
    },
    {
      "id": 73,
      "seek": 44224,
      "start": 443.24,
      "end": 451.52,
      "text": " And then what you'll do is like, if a supercluster has a modifier of 2, we'll say, and then within",
      "tokens": [
        50413,
        843,
        788,
        644,
        345,
        1183,
        466,
        318,
        588,
        11,
        611,
        257,
        2208,
        565,
        5819,
        468,
        257,
        23157,
        286,
        362,
        11,
        356,
        1183,
        910,
        11,
        290,
        788,
        1626,
        50827
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14037834803263347,
      "compression_ratio": 1.4485294117647058,
      "no_speech_prob": 0.955777645111084
    },
    {
      "id": 74,
      "seek": 44224,
      "start": 451.52,
      "end": 466.64,
      "text": " that you've got a cluster which has a modifier of 0.15, that should be, somehow I want that",
      "tokens": [
        50827,
        326,
        345,
        1053,
        1392,
        257,
        13946,
        543,
        468,
        257,
        23157,
        286,
        657,
        13,
        1314,
        11,
        326,
        815,
        307,
        11,
        7599,
        314,
        765,
        326,
        51583
      ],
      "temperature": 0.0,
      "avg_logprob": -0.14037834803263347,
      "compression_ratio": 1.4485294117647058,
      "no_speech_prob": 0.955777645111084
    },
    {
      "id": 75,
      "seek": 46664,
      "start": 466.64,
      "end": 474.56,
      "text": " to be like, how does this thing relative to the other things within this change?",
      "tokens": [
        50363,
        284,
        307,
        588,
        11,
        703,
        857,
        428,
        1517,
        3585,
        284,
        262,
        584,
        1243,
        1626,
        428,
        1487,
        30,
        50759
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12125485068873355,
      "compression_ratio": 1.7282051282051283,
      "no_speech_prob": 0.7842337489128113
    },
    {
      "id": 76,
      "seek": 46664,
      "start": 474.56,
      "end": 481.08,
      "text": " So that's gonna be, you start at a base urgency of 1, right?",
      "tokens": [
        50759,
        1406,
        326,
        338,
        8066,
        307,
        11,
        345,
        923,
        379,
        257,
        2779,
        25615,
        286,
        352,
        11,
        826,
        30,
        51085
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12125485068873355,
      "compression_ratio": 1.7282051282051283,
      "no_speech_prob": 0.7842337489128113
    },
    {
      "id": 77,
      "seek": 46664,
      "start": 481.08,
      "end": 488.15999999999997,
      "text": " The actual task is an urgency of 1, then if it's in a galaxy, you want to compare to other",
      "tokens": [
        51085,
        383,
        4036,
        4876,
        318,
        281,
        25615,
        286,
        352,
        11,
        788,
        611,
        340,
        338,
        287,
        257,
        16161,
        11,
        345,
        765,
        284,
        8996,
        284,
        584,
        51439
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12125485068873355,
      "compression_ratio": 1.7282051282051283,
      "no_speech_prob": 0.7842337489128113
    },
    {
      "id": 78,
      "seek": 46664,
      "start": 488.15999999999997,
      "end": 489.15999999999997,
      "text": " galaxies right?",
      "tokens": [
        51439,
        27982,
        826,
        30,
        51489
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12125485068873355,
      "compression_ratio": 1.7282051282051283,
      "no_speech_prob": 0.7842337489128113
    },
    {
      "id": 79,
      "seek": 46664,
      "start": 489.15999999999997,
      "end": 495.68,
      "text": " So if the galaxy has a modifier of 1.5, and another galaxy has a modifier of 1, then the",
      "tokens": [
        51489,
        1406,
        611,
        262,
        16161,
        468,
        257,
        23157,
        286,
        352,
        13,
        20,
        11,
        290,
        1194,
        16161,
        468,
        257,
        23157,
        286,
        352,
        11,
        788,
        262,
        51815
      ],
      "temperature": 0.0,
      "avg_logprob": -0.12125485068873355,
      "compression_ratio": 1.7282051282051283,
      "no_speech_prob": 0.7842337489128113
    },
    {
      "id": 80,
      "seek": 49568,
      "start": 495.72,
      "end": 500.48,
      "text": " urgency of the first galaxy is 1.5, okay.",
      "tokens": [
        50365,
        25615,
        286,
        262,
        717,
        16161,
        318,
        352,
        13,
        20,
        11,
        8788,
        13,
        50603
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13820256256475683,
      "compression_ratio": 1.6149732620320856,
      "no_speech_prob": 0.791230320930481
    },
    {
      "id": 81,
      "seek": 49568,
      "start": 500.48,
      "end": 506.16,
      "text": " Then within that you've got a cluster, the cluster has a modifier of 2 for instance,",
      "tokens": [
        50603,
        3244,
        1626,
        326,
        345,
        1053,
        1392,
        257,
        13946,
        11,
        262,
        13946,
        468,
        257,
        23157,
        286,
        362,
        329,
        4554,
        11,
        50887
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13820256256475683,
      "compression_ratio": 1.6149732620320856,
      "no_speech_prob": 0.791230320930481
    },
    {
      "id": 82,
      "seek": 49568,
      "start": 506.16,
      "end": 516.8,
      "text": " so then it would be whatever the resulting urgency at the galaxy level is, you multiply",
      "tokens": [
        50887,
        523,
        788,
        340,
        561,
        307,
        4232,
        262,
        7186,
        25615,
        379,
        262,
        16161,
        1241,
        318,
        11,
        345,
        29162,
        51419
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13820256256475683,
      "compression_ratio": 1.6149732620320856,
      "no_speech_prob": 0.791230320930481
    },
    {
      "id": 83,
      "seek": 49568,
      "start": 516.8,
      "end": 524.16,
      "text": " that by the cluster level, so that would be 1.5 times 2 would give it a thing of 3, but",
      "tokens": [
        51419,
        326,
        416,
        262,
        13946,
        1241,
        11,
        523,
        326,
        561,
        307,
        352,
        13,
        20,
        1661,
        362,
        561,
        1577,
        340,
        257,
        1517,
        286,
        513,
        11,
        475,
        51787
      ],
      "temperature": 0.0,
      "avg_logprob": -0.13820256256475683,
      "compression_ratio": 1.6149732620320856,
      "no_speech_prob": 0.791230320930481
    },
    {
      "id": 84,
      "seek": 52416,
      "start": 524.16,
      "end": 533.88,
      "text": " then within the supercluster, it's got a modifier of fucking 0.1, and does that mean",
      "tokens": [
        50363,
        788,
        1626,
        262,
        2208,
        565,
        5819,
        11,
        340,
        338,
        1392,
        257,
        23157,
        286,
        9372,
        657,
        13,
        16,
        11,
        290,
        857,
        326,
        1612,
        50849
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21466651227739122,
      "compression_ratio": 1.5114942528735633,
      "no_speech_prob": 0.08845125883817673
    },
    {
      "id": 85,
      "seek": 52416,
      "start": 533.88,
      "end": 538.64,
      "text": " the final modifier should be 0.3?",
      "tokens": [
        50849,
        262,
        2457,
        23157,
        815,
        307,
        657,
        13,
        18,
        30,
        51087
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21466651227739122,
      "compression_ratio": 1.5114942528735633,
      "no_speech_prob": 0.08845125883817673
    },
    {
      "id": 86,
      "seek": 52416,
      "start": 538.64,
      "end": 543.12,
      "text": " Final urgency should be 0.3, does that make sense?",
      "tokens": [
        51087,
        8125,
        25615,
        815,
        307,
        657,
        13,
        18,
        11,
        857,
        326,
        787,
        2565,
        30,
        51311
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21466651227739122,
      "compression_ratio": 1.5114942528735633,
      "no_speech_prob": 0.08845125883817673
    },
    {
      "id": 87,
      "seek": 52416,
      "start": 543.12,
      "end": 549.0,
      "text": " I think so, because that would mean that like, essentially no matter how important the object",
      "tokens": [
        51311,
        314,
        892,
        523,
        11,
        780,
        326,
        561,
        1612,
        326,
        588,
        11,
        6986,
        645,
        2300,
        703,
        1593,
        262,
        2134,
        51605
      ],
      "temperature": 0.0,
      "avg_logprob": -0.21466651227739122,
      "compression_ratio": 1.5114942528735633,
      "no_speech_prob": 0.08845125883817673
    },
    {
      "id": 88,
      "seek": 54900,
      "start": 549.0,
      "end": 558.36,
      "text": " is within, well, so it's the question of, if I've said this supercluster is very important,",
      "tokens": [
        50363,
        318,
        1626,
        11,
        880,
        11,
        523,
        340,
        338,
        262,
        1808,
        286,
        11,
        611,
        314,
        1053,
        531,
        428,
        2208,
        565,
        5819,
        318,
        845,
        1593,
        11,
        50831
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11368025050443761,
      "compression_ratio": 1.74,
      "no_speech_prob": 0.5869329571723938
    },
    {
      "id": 89,
      "seek": 54900,
      "start": 558.36,
      "end": 568.56,
      "text": " so it has a positive modifier, do I then want to say a very unimportant task within this",
      "tokens": [
        50831,
        523,
        340,
        468,
        257,
        3967,
        23157,
        11,
        466,
        314,
        788,
        765,
        284,
        910,
        257,
        845,
        555,
        18049,
        4876,
        1626,
        428,
        51341
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11368025050443761,
      "compression_ratio": 1.74,
      "no_speech_prob": 0.5869329571723938
    },
    {
      "id": 90,
      "seek": 54900,
      "start": 568.56,
      "end": 575.18,
      "text": " is more important than a very important task within an unimportant supercluster?",
      "tokens": [
        51341,
        318,
        517,
        1593,
        621,
        257,
        845,
        1593,
        4876,
        1626,
        281,
        555,
        18049,
        2208,
        565,
        5819,
        30,
        51672
      ],
      "temperature": 0.0,
      "avg_logprob": -0.11368025050443761,
      "compression_ratio": 1.74,
      "no_speech_prob": 0.5869329571723938
    },
    {
      "id": 91,
      "seek": 57518,
      "start": 575.18,
      "end": 578.14,
      "text": " And I think the answer is yes.",
      "tokens": [
        50363,
        843,
        314,
        892,
        262,
        3280,
        318,
        3763,
        13,
        50511
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2147087568647406,
      "compression_ratio": 1.8219895287958114,
      "no_speech_prob": 0.7843421101570129
    },
    {
      "id": 92,
      "seek": 57518,
      "start": 578.14,
      "end": 586.4599999999999,
      "text": " And so what I think I will need to do is I essentially want to, there'll be multiplicative",
      "tokens": [
        50511,
        843,
        523,
        644,
        314,
        892,
        314,
        481,
        761,
        284,
        466,
        318,
        314,
        6986,
        765,
        284,
        11,
        612,
        1183,
        307,
        15082,
        43058,
        50927
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2147087568647406,
      "compression_ratio": 1.8219895287958114,
      "no_speech_prob": 0.7843421101570129
    },
    {
      "id": 93,
      "seek": 57518,
      "start": 586.4599999999999,
      "end": 588.9399999999999,
      "text": " and there'll be additive I think.",
      "tokens": [
        50927,
        290,
        612,
        1183,
        307,
        38298,
        314,
        892,
        13,
        51051
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2147087568647406,
      "compression_ratio": 1.8219895287958114,
      "no_speech_prob": 0.7843421101570129
    },
    {
      "id": 94,
      "seek": 57518,
      "start": 588.9399999999999,
      "end": 597.66,
      "text": " So for the medical cluster, within the medical cluster you can have multiplicative things,",
      "tokens": [
        51051,
        1406,
        329,
        262,
        3315,
        13946,
        11,
        1626,
        262,
        3315,
        13946,
        345,
        460,
        423,
        15082,
        43058,
        1243,
        11,
        51487
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2147087568647406,
      "compression_ratio": 1.8219895287958114,
      "no_speech_prob": 0.7843421101570129
    },
    {
      "id": 95,
      "seek": 57518,
      "start": 597.66,
      "end": 602.9,
      "text": " but you should then add, and the multiplicative things importantly should be between 0 and",
      "tokens": [
        51487,
        475,
        345,
        815,
        788,
        751,
        11,
        290,
        262,
        15082,
        43058,
        1243,
        11003,
        815,
        307,
        1022,
        657,
        290,
        51749
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2147087568647406,
      "compression_ratio": 1.8219895287958114,
      "no_speech_prob": 0.7843421101570129
    },
    {
      "id": 96,
      "seek": 57518,
      "start": 602.9,
      "end": 603.9399999999999,
      "text": " 2 I think.",
      "tokens": [
        51749,
        362,
        314,
        892,
        13,
        51801
      ],
      "temperature": 0.0,
      "avg_logprob": -0.2147087568647406,
      "compression_ratio": 1.8219895287958114,
      "no_speech_prob": 0.7843421101570129
    },
    {
      "id": 97,
      "seek": 60394,
      "start": 603.94,
      "end": 610.82,
      "text": " I think that should stop it from ever like, going out of hand and overtaking, because",
      "tokens": [
        50363,
        314,
        892,
        326,
        815,
        2245,
        340,
        422,
        1683,
        588,
        11,
        1016,
        503,
        286,
        1021,
        290,
        9929,
        868,
        11,
        780,
        50707
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18036463856697083,
      "compression_ratio": 1.4795321637426901,
      "no_speech_prob": 0.004417960532009602
    },
    {
      "id": 98,
      "seek": 60394,
      "start": 610.82,
      "end": 618.7,
      "text": " as far as I can tell, the maximum urgency that you get is somewhere below 10.",
      "tokens": [
        50707,
        355,
        1290,
        355,
        314,
        460,
        1560,
        11,
        262,
        5415,
        25615,
        326,
        345,
        651,
        318,
        7382,
        2174,
        838,
        13,
        51101
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18036463856697083,
      "compression_ratio": 1.4795321637426901,
      "no_speech_prob": 0.004417960532009602
    },
    {
      "id": 99,
      "seek": 60394,
      "start": 618.7,
      "end": 626.62,
      "text": " I mean I can look at the urgency calculation actually, yeah, and then figure out what the",
      "tokens": [
        51101,
        314,
        1612,
        314,
        460,
        804,
        379,
        262,
        25615,
        17952,
        1682,
        11,
        10194,
        11,
        290,
        788,
        3785,
        503,
        644,
        262,
        51497
      ],
      "temperature": 0.0,
      "avg_logprob": -0.18036463856697083,
      "compression_ratio": 1.4795321637426901,
      "no_speech_prob": 0.004417960532009602
    },
    {
      "id": 100,
      "seek": 62662,
      "start": 626.62,
      "end": 638.62,
      "text": " double the maximum urgency is, so if the additive, if the additive modifier is greater",
      "tokens": [
        50363,
        4274,
        262,
        5415,
        25615,
        318,
        11,
        523,
        611,
        262,
        38298,
        11,
        611,
        262,
        38298,
        23157,
        318,
        3744,
        50963
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1866255708642908,
      "compression_ratio": 1.6868131868131868,
      "no_speech_prob": 0.28700459003448486
    },
    {
      "id": 101,
      "seek": 62662,
      "start": 638.62,
      "end": 646.34,
      "text": " than that double value, then we can guarantee that no matter how important or unimportant",
      "tokens": [
        50963,
        621,
        326,
        4274,
        1988,
        11,
        788,
        356,
        460,
        9149,
        326,
        645,
        2300,
        703,
        1593,
        393,
        555,
        18049,
        51349
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1866255708642908,
      "compression_ratio": 1.6868131868131868,
      "no_speech_prob": 0.28700459003448486
    },
    {
      "id": 102,
      "seek": 62662,
      "start": 646.34,
      "end": 652.5,
      "text": " tasks are, this supercluster should be the most important, should have the biggest urgency.",
      "tokens": [
        51349,
        8861,
        389,
        11,
        428,
        2208,
        565,
        5819,
        815,
        307,
        262,
        749,
        1593,
        11,
        815,
        423,
        262,
        4094,
        25615,
        13,
        51657
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1866255708642908,
      "compression_ratio": 1.6868131868131868,
      "no_speech_prob": 0.28700459003448486
    },
    {
      "id": 103,
      "seek": 62662,
      "start": 652.5,
      "end": 654.34,
      "text": " Yeah, that makes a lot of sense, okay.",
      "tokens": [
        51657,
        9425,
        11,
        326,
        1838,
        257,
        1256,
        286,
        2565,
        11,
        8788,
        13,
        51749
      ],
      "temperature": 0.0,
      "avg_logprob": -0.1866255708642908,
      "compression_ratio": 1.6868131868131868,
      "no_speech_prob": 0.28700459003448486
    },
    {
      "id": 104,
      "seek": 65434,
      "start": 654.34,
      "end": 658.7,
      "text": " So that'd be awesome, that'd be really useful I think.",
      "tokens": [
        50363,
        1406,
        326,
        1549,
        307,
        7427,
        11,
        326,
        1549,
        307,
        1107,
        4465,
        314,
        892,
        13,
        50581
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3022690667046441,
      "compression_ratio": 1.3070175438596492,
      "no_speech_prob": 0.18216361105442047
    },
    {
      "id": 105,
      "seek": 65434,
      "start": 658.7,
      "end": 660.86,
      "text": " We'll look into that, that's a cool thing.",
      "tokens": [
        50581,
        775,
        1183,
        804,
        656,
        326,
        11,
        326,
        338,
        257,
        3608,
        1517,
        13,
        50689
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3022690667046441,
      "compression_ratio": 1.3070175438596492,
      "no_speech_prob": 0.18216361105442047
    },
    {
      "id": 106,
      "seek": 65434,
      "start": 660.86,
      "end": 663.58,
      "text": " I'm gonna stop talking now and get back to driving.",
      "tokens": [
        50689,
        314,
        1101,
        8066,
        2245,
        3375,
        783,
        290,
        651,
        736,
        284,
        5059,
        13,
        50825
      ],
      "temperature": 0.0,
      "avg_logprob": -0.3022690667046441,
      "compression_ratio": 1.3070175438596492,
      "no_speech_prob": 0.18216361105442047
    }
  ],
  "language": "English"
}